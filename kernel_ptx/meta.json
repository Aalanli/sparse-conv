{
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ecb67c0ae44e5998eea81c7ad11ff5f9a0e46ebfe646ee8e2144db470270f551",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d2fb9cb9192a8932f9f9826f8c774f357c89354127f6237e8a46ca6e41b88769",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "b01d8e6e22a04c0bae6e4f71b2f19b272504154ddab661db728656e41e3f34ff",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3c53ad476a030103dd700bfaf735ddbb0fda7f8bdda22b08b46e5e3ca3cfa0e0",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2e48b35434a82710c17764ab249dd12f75077e40189a0c397d90add4e3f99715",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3400fb2069d9e8de3218ac7f19d3f9ed3d5c8801ac13da7bb8e88e20d5b815d7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "11541591f21ef16c96bd942432ed0229c3fc922f3c3e009a43e0d32499a5cf9c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d83d050a3cf93fe2dead48cc0b165e25584b04255243b52fbe4de19b30fcb346",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "9b4da48805847affee74a4cff575c326c1562689b20b30ad7c7f63e3e9668402",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2112,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5324595d62e0864a645b0bbb2dd056f6eb5786afd154c97a9927e87d8eea8863",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "4744dafb0ed555382451fdffc939ded826508ecff5663a8aba0b9bbc622cfdc8",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6839a2932717ccbbec2217f89d61c6642140f43f3ba7b9743af982c6a499dd07",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2de15238039db9f13dca9a400b6805129da72538c165ba89a03402983ceaaa12",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "9fb87b72c19aa8930384666c3d8bae15fee21a150113e7dafa8708af2b677a89",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a95bd6d8b490205598489ed2ed8ab1fa4c1cd22e8cd5739ce1f777fbbe272623",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "e35ed1083ecd6ffc8f1f7ff91894052665080ac91a5d2415cb01eace388a4261",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "795b9daa941d29d261f7efbfe1caaea17c4f302d126eb3e47149aff6118deefb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2be57f2f33a4f90e5fbcc86d1397329e67196c8aeaa454cb96fbe97a4d5d6d2d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2112,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "fadb976d0a503ee40c7f32f6ac98a9adc91af27d33134b5392f47deb62984714",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "e97a7a9e6c95e86cd401a0a44719f7379591dc61e55d33f0abceaaf3f5d376d9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "47ab59c9b6f7bf9c3fdbf418bfa09eaa0001639b4267cefac3c12ea102e6cff6",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "05edb452e4afc154242f062f5aed8934e8def5a02ecd75ace3e3c6a301fd86d3",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "9c3a5c52184f8f76c902497f90afa5ed1110a7ff2141843840b4ff930a9f113c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2adefeb6676f1deace4be98d6d6eae838f40ca94f34732fb88c583515477a926",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ee547f7bd0b60447af3f36a24e7046ea4509c7d3dbfb063cf73109d24c756f18",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a2436fc1ee9d7f7fa50970246df933bd88e351394f66754761fe2422b131e3a9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=75).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 75
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm75",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "73a184ea54039a60c368beb905608b065c33fd1e8927f7df8a315907886233d2",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2112,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a4614ba6e245d2eab08cef12b9a6ae207003af4ee4c1ca266fb2fa5ac083d260",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "fe475bde25a95b1bb6a6dbcb1745204c8e19558ce66f35b91ec238beb67a2485",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "76a8a20b1ba51b724fcf5d84d057a295c80468ef36046302f66c700a12fd0d22",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d96eb2cb786b7345be74ddb04447d7ad25a6d53ded2f005a1cb51e7082dafd89",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "b9cf5b711fde303bed28d5035e1f480aad918b99542809c8e2aed3d84cb5eab7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 18432,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "b9ba4ab77703f32a888e0b69cc8a3e0fc64acac42b9466bba854c36a4bbabc81",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3f39bee38659d4042ce648a48ee1d244c5f8315d002634c4defeb87552d83948",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "8f459b84f5aa65e9ec0ea35d25f15fc2a31b348ee1772eef80bbbc23210a9c16",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "baf2ffe6d41bf49b8a686cab43f1f68b136686fbdda6190844a0431858bf51da",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "66f853024289bc70539679f47450ae688afe88ee59ef898b8859533d4815b6fb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "1551c1f71d3967461989956375e61bbc6d562c86fa917912d7257c5b0bbeae05",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "553e587e87cab7185b38f07dd029666bf15b35b57f94c7fc7a443f8afef06f45",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "dc301ef7399a39e2f60af1eabe67f189004b38b759ec7de6776dea268b66ac29",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5c38f58d69d43d8a4ae97215c0279191ee26de474b2f9e42b21cbe770ce92c4e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 17408,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "b5c2bfe21e3952064bdc2634b288487e48bdada5e7060e157f25fc6f09162ae6",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6d9edc4539aba4e81ab875a8d6693d61699e12c04a16fbd0ede9eeae48f646c0",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 18432,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bb2dd5e81447861b39459b4ce5e905889659e60bb16f77d094ddac02a2547a0f",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ecd8dad27dc63aaa8a68df25547c4466ba7eaa1b2ffde7bd9a6d2edbc48f29ae",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "e72220246cb04636601726ecfb03ae5621f9fd4ab07bd2d8c04116eaaedff2ed",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bd4d304b821a607f38ffd3c332f1d67b8169e6d60f4bc1d4a993d6facddbbd39",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "69b2c2f9b54b33ce91518a767db44e95f1fc5d19b2573904d504557172fcfc5e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "0c8f2d6259cc6bcb786817da1a78d4531ffe576cf7c2baf511ad1165da4cef9b",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "52d789505ebf9fa2908563673c6af9f500b5c2e7906abf9f551265bbe695a434",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ad5af25afcfb869c6be603a2606767f3892663b5568ee9b114e05ad214057f4e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3f6899c39d03c0bd9631d4a4454695ad1ad19836b38d46845acd47ce1ddfaab8",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "31f9b3003ca724e20469a67be34344790cbffa2f9f1a6056ca24d4403e5c4e70",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=86).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "58583140885adb938f14d48efa5594dc7d5ce047da8bd15aa4ce6aa0b92ac84a",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "645ce8bb3a1223452d9e6eac1aa39ae8954972284f4f1ac80a8d8730c666ffe4",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "30885d44fb64b42c817f8fb175fa3e093749915860f7321cd1c8f31cf8f964ef",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "26d2c92e51a942272228969ef2d12048f21c6361b8875514c919c52898a76386",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "c18a537380177c9c10a9f878c51292ed123ce7e4579a5538c9d16518743502b5",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "b435eda9f4f6a527dd761064e8b840a15609849c46cef6c56757ed7f310875e2",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 18432,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "71af2fe08085cf7a1e893aaf6ae164a76b1c1ef652e3331e1e5963d281b8985e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f53775679b0a1bb671164b7c494336b6ba3ed3cb3b120b43b7b32a5ad4bf6d5e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f9c7cf29b4ddb960211df4dc03228c8358bd65dec1f2b6bcfa7d000c3bc79dae",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=True, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ee82d8634cce9f9e61da5ba1b851618cc6885b47e607843ee628edbad83cb207",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6d32f77a46f6466235317a78ef30513f355cfbcf23b19fa077be14bad540da5e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "dbfc1787588124301db4584d21e146138d30582d338b23c2fd1a7c9950490148",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "9df2f65d9d2b32cb5a313ca4f6deadb822c09e7e9c14c6e0254766bc283ce7ab",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "011b730241705342824922032c55685367810624d6bf772bff14e724dec37bab",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "0023345f9149d51096822c28a75387b7a39afe0954f87ecf87f2abe849de5a6b",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 17408,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "19a82f4211db6d379af348fc40e5d027b52191c768dfdffd6583eeb65c0859e0",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6ba2ef712bfc29e456c2dc2ab569a021cefb81aec8c2819e074d2cdeb9034b1c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 18432,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "7b247c26b163acfc193aabb34771b7cbb70cc679e1d3e7863b0ac9bf9fb1b34f",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=True, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": true,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "64a3b4e9c47da41f10576fb1c53362711a614f51d12d6c4807b24316250340e5",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "c7042c97816b749f2149e127bde113e0d35fded341e13521e1b6ccc88a0d0ff8",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 16, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 16,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "57f204a0ce376082fcda5be1aa378214f791f97efe07a8e2484c3824320a5e50",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "44b09b849ae407c18b762ae482b2149a2a87c74f28ea17c28f772f583c882220",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 32, 'BLOCK_Dp': 16}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 32,
                "BLOCK_Dp": 16
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "85a487e84828a2a53511893d2b9e0382700f906a278553b82763890c54014740",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 128}, num_warps=8, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 128
            },
            "num_warps": 8,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "4bb80f1cdd54bee79034dbf74322bf0acb1f7307e67ecb8f6e9998d32d5ef9d4",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 8,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 128, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=4, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 128,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 4,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "78dd3a09e9ab029086830db4199e399d4088dcb828ac42d4f53b424e2903a237",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 64, 'BLOCK_Dp': 64}, num_warps=4, num_stages=3, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 64,
                "BLOCK_Dp": 64
            },
            "num_warps": 4,
            "num_stages": 3,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "23af6d2ff048bb44ee9212aa49b2f68279bbfc6061557a05d9b667bbcf9c9ed5",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 3,
            "num_warps": 4,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 16, 'BLOCK_K': 32, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 16,
                "BLOCK_K": 32,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "7cae35ce6761846c4b6f816ca7364011fcc80120cd25f0886b6c13d63f45a2a0",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(block_sizes={'BLOCK_N': 32, 'BLOCK_K': 16, 'BLOCK_Dp': 32}, num_warps=2, num_stages=2, div_k=False, div_d=False, div_dp=False, dtype='fp16', sm=89).ptx": {
        "config": {
            "block_sizes": {
                "BLOCK_N": 32,
                "BLOCK_K": 16,
                "BLOCK_Dp": 32
            },
            "num_warps": 2,
            "num_stages": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "dtype": "fp16",
            "sm": 89
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm89",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "79bc6fdcf416da7d6eb675f5d6c91019d33c8dd61f9678b6459ad7a807c11d16",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": null,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e4nv",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    }
}