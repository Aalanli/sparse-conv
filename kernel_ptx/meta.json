{
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "1cc53c6126487207af4b493ca45dc4898bf0a3aef5a2307421df7c7ddf0f90c7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "977fbe7128891fc3ff6fcb16675cb1db3c5b7f55c8e0bcfd2c247a80fad75fa9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "1db5bb5a73d9182aa94ac0e66dd6bf5e62c20151f7ce75aa0f219cb9ce3547e7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a63d739a1963adfbfb6121a2971884d91c6668aade7ec0f53242cbe49dfd7178",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "182ace665ffdfe628e8de82169ced2bbbe57809d4b4c299761a22648602bf416",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "8c9df12f0542589fa6bd3b441310f69960973df1ded8ee2fd7e4dac53fe5580c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=128, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 128,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ced61da431a270b988463fd365adec1237de26568e07475924928430a4c63d64",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "8c9df12f0542589fa6bd3b441310f69960973df1ded8ee2fd7e4dac53fe5580c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bd4fe45e01e29b5d29da4ed73cfab25db1ca7087c0466490ab6b893cfefd6dc9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "31c6f19e3242afb144fda984646a48b341a2247b5dd8833bc3e492d18b7b69fa",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ee0a2138e77831a88f4990ab58997f4bc54b14254699f53f36a4786ba255254d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bb93aecc74084b596d4c1a916e9bad83f151c18ec3760b1f1a3f0fd369b61cc4",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bd4fe45e01e29b5d29da4ed73cfab25db1ca7087c0466490ab6b893cfefd6dc9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a652a9025df9ce14a0f83e80c8b4a015655073ba93731b0af31929812ad19f15",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 4096,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "af12b32930e43e0f27a455e8952935afbeda0abc02095bbe603c1106f61158f9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ee5cef2ffc8338e2d5025009ec419fbfd12629c0f9c182ee8ebc5690923af90d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "31c6f19e3242afb144fda984646a48b341a2247b5dd8833bc3e492d18b7b69fa",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "7d42e8b2b048c3ecc82018debec9a541c6e4ac2b2154c0aca31f4e641b9a8234",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f4aaf5db17893850d69759d023497572655a453f75f7c5bd6688fb5a9c3c4182",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d0f05e78f1a8e0464431f828130bdf26efe959f96ab3b84c570fd9e59534c399",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "7d42e8b2b048c3ecc82018debec9a541c6e4ac2b2154c0aca31f4e641b9a8234",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "af12b32930e43e0f27a455e8952935afbeda0abc02095bbe603c1106f61158f9",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d8ffa6dfa2bbf42f8e6ed5e9a53eab2d4cbbea11a6cf19083ae0ffb0b0da79e4",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "de031ff31675650431a412c615ed4c9bae856beb5d3245d3d490e982d2c79cdb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6f097887fee676045cd9135029ee0b99f34bba9d739d2f5a4d021b16066153b3",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ca9bab8cccb0030de1c94e778b475a45693fec9c38f56c525dc88e7a0d8778bd",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "fac7024b760b3937410a2f6d8df82450fc730fd0e11a33b36ccd620e8f86ded8",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "63f5834d314953a73ab998f26dad182292872dff6230ab9ba2ad1bdab84a8e60",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 4096,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=128, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 128,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ba66e92e1e4541afa6dea429167f7bf2ef06bce5248f83d8218134509a392d83",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "98e5db7d308cfc91f12cbe531207ecedc792c3c7801c4e5610a1ff127adf936c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "98e5db7d308cfc91f12cbe531207ecedc792c3c7801c4e5610a1ff127adf936c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "00a72fc093ad9842892b7c43283fb099b59929991f2efbc6517cc3c7b8084622",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "afee8c572c697ee42679224afe7a5f6b21603c7c0fe2ef4ad7ed1008f411cb15",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d06b0e92ab41149ec0e27f010d828ae9688a66afa32d9faea386ff126b6f4bbd",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "adce2e7a2e9b807c59482c9098aebb8b24ef161b93cb94d50194aa39be14be68",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "8f534447e57333aefc21cf5593ef0ba77fccfd6f58a59762e99945d134bc5b3d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5a84226700df59fc9cf836ee599b3e4313979e2d100cf1c2771421f52267e5ad",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "4d78611633598dd9e2082f4f456d56396e93d1e37e751b1b9386e4f248cba636",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "ca9bab8cccb0030de1c94e778b475a45693fec9c38f56c525dc88e7a0d8778bd",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "239f65a28e94043e2274443cad5fc05a3af6900d399d8af976eecdbeca48f863",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bcd9b67a336fbbfd5795fe79ea6e9270c837d7c5c8f70905de7570d3ce57ca76",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "239f65a28e94043e2274443cad5fc05a3af6900d399d8af976eecdbeca48f863",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "bcd9b67a336fbbfd5795fe79ea6e9270c837d7c5c8f70905de7570d3ce57ca76",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=1, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 1,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "adce2e7a2e9b807c59482c9098aebb8b24ef161b93cb94d50194aa39be14be68",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "89ee5fe94b03af7aaa9bd2b80f541485b7bc5b6c6e079f9a20666b310c468c4c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5ea1399a6c0f182a182add57fb13867b031da5d4351500103369ad24eb15f28c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d663688635ec7212b22038489a1680507678d408acb3c5d705e7638b1eb9b3ec",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "79c00e2f41ada00fc4a8031ca8156bf32427eff0b5d4c07787c9c6c9e9fc55a4",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5ad0878cb5ede2a810b4747c58320c5fed29138723c1b0f4eb9be53c8d338d99",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "824957b2412a8f555e9f8a266208889e55dbb793df388cf33715f17c93309186",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "10e1eb2167af59ed1a0a139b71dcbfcc0df1c5083fb987a4802534fcaa41090f",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "937f88c63213045c407b351082067730c1b264a2595bdd5d8f55f9ee62ab11e3",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "321047231233e8e47aac8cc2bc9152caef6ad0d2de5c0af7df005a563988f078",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5102d603e4152c91607b134f4ba6256e84356b45f28cefea1ca9a2dbbc155e81",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "937f88c63213045c407b351082067730c1b264a2595bdd5d8f55f9ee62ab11e3",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "51702633654cc0109b03ba0f4e73354948dc387f0676dadd15e6ab4d474430cb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "c14408af99ccde495146e492a4301e9dcccace31ab6540400bf122cb198c56e6",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=128, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 128,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6d940f8b2acd52af506e86608445cdf379d3b8b80deb94dfe9f9707c1087cf91",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2ff4cf2a0bbd6151ce60ffe9aff0687d9ced2b11fbc2e2af050de72987df8f2d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "10e1eb2167af59ed1a0a139b71dcbfcc0df1c5083fb987a4802534fcaa41090f",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "671ab3e415d6691130c4dfc8f41c878ec22713e0602c6ba19ed0672f7471af44",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "89ee5fe94b03af7aaa9bd2b80f541485b7bc5b6c6e079f9a20666b310c468c4c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "2ff4cf2a0bbd6151ce60ffe9aff0687d9ced2b11fbc2e2af050de72987df8f2d",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "51702633654cc0109b03ba0f4e73354948dc387f0676dadd15e6ab4d474430cb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "5bbb3b6d376c63c668c4ed50f70a58e26351e8d35979e8e739b1ada89a9251e3",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=True, div_dp=True, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": true,
            "div_dp": true,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "4aaf16d5dc474f33e2bec5be0c74f4ebcbdf0796f872d118f050cce6a9a43753",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 4096,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3314431bef6a15b8d44400cdbd068cb8cb03a821abb296bea62ea303eaa794a7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6a467bb71930df1912f9c21073ee555e977701c902a57e9852d28473ac9859cb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=128, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 128,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "8c3d7bc6e074fd95a03cfcb0dd34593ba8ae83278cf134c6318b4284039e6869",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 9216,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f3b61f05a17b4b73ef99b93368b98fe67ee3b86b5295af53adc6ab50a02ffdf7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "de50dd5d695eaad4c3de280b83471be270e2677cbfbdb53597a4ca5ba508134e",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "0fa5a8e2cb3d152d4eca199671fa48b82b089ab9bf1c10162e07a6cbd1922723",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d72467c0fa946eaf690feab10b8cfc7fc3a5b2dc610f76d67a3c9b31813ac201",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 4096,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d053a5dab02f3e19be7dbcef11e209f0c25ac0cba52a5bde382d390829619b58",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=32, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 32,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "fa9364371a3db410e8e755d532987071c822ef5a4159aa77e47ef6a12387387c",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "de72f935b671b725460fa87a5203316384eaf4a09f4a43970c4fc55f8869f769",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 6144,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "0b70113e097afcb64d4e39e30def1ddf02cc00bdcc9e9a598754048b63bf8641",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=64, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 64,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6a467bb71930df1912f9c21073ee555e977701c902a57e9852d28473ac9859cb",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f34be62916c762a89ac37f60e34a3e1c39cdc96138e3cc4789f7e2c0b46e8f56",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "f3b61f05a17b4b73ef99b93368b98fe67ee3b86b5295af53adc6ab50a02ffdf7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1024,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "d053a5dab02f3e19be7dbcef11e209f0c25ac0cba52a5bde382d390829619b58",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 3072,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "0b70113e097afcb64d4e39e30def1ddf02cc00bdcc9e9a598754048b63bf8641",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 1536,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp16', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp16",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "6f31b2e00ce3f7228165875c6f64a8eea4319e0525dbeabd39377763f115f8aa",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=16, BLOCK_Dp=16, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 16,
            "BLOCK_Dp": 16,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "165a213bad3b18a4c0b236e061a6135cdf7862515f3a3a6e4b6e48a912ad42ac",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "680444bd985e2acbfca8255e7bb36ba0ddf548a1e86bd99bec5c15f147a00050",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 5120,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=16, BLOCK_K=32, BLOCK_Dp=64, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 16,
            "BLOCK_K": 32,
            "BLOCK_Dp": 64,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "a6d278dbebd09afa15a0a7248ba645367dea80939c71068371e4ee6007a6d714",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 10240,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=32, BLOCK_K=16, BLOCK_Dp=32, num_warps=2, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp16', sm=86).ptx": {
        "config": {
            "BLOCK_N": 32,
            "BLOCK_K": 16,
            "BLOCK_Dp": 32,
            "num_warps": 2,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp16",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "3314431bef6a15b8d44400cdbd068cb8cb03a821abb296bea62ea303eaa794a7",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 2,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 2048,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    },
    "Config(BLOCK_N=128, BLOCK_K=32, BLOCK_Dp=32, num_warps=4, num_stages=2, parallel_k=2, div_k=False, div_d=False, div_dp=False, acc_dtype='fp32', dtype='fp32', sm=86).ptx": {
        "config": {
            "BLOCK_N": 128,
            "BLOCK_K": 32,
            "BLOCK_Dp": 32,
            "num_warps": 4,
            "num_stages": 2,
            "parallel_k": 2,
            "div_k": false,
            "div_d": false,
            "div_dp": false,
            "acc_dtype": "fp32",
            "dtype": "fp32",
            "sm": 86
        },
        "meta": {
            "allowed_dot_input_precisions": [
                "tf32",
                "tf32x3",
                "ieee"
            ],
            "arch": "sm86",
            "backend_name": "cuda",
            "cluster_dims": [
                1,
                1,
                1
            ],
            "debug": false,
            "default_dot_input_precision": "tf32",
            "deprecated_fp8_dtypes": [],
            "enable_fp_fusion": true,
            "extern_libs": [
                [
                    "libdevice",
                    "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"
                ]
            ],
            "global_scratch_align": 1,
            "global_scratch_size": 0,
            "hash": "fdc777c2e496d1993acb98b47010c6154f964076c44c2659eda4e8d6a4b98730",
            "launch_cooperative_grid": false,
            "max_num_imprecise_acc_default": 0,
            "maxnreg": null,
            "name": "implicit_conv3d_kernel",
            "num_buffers_warp_spec": 0,
            "num_consumer_groups": 0,
            "num_ctas": 1,
            "num_stages": 2,
            "num_warps": 4,
            "ptx_version": 82,
            "reg_dec_producer": 0,
            "reg_inc_consumer": 0,
            "sanitize_overflow": true,
            "shared": 20480,
            "supported_fp8_dtypes": [
                "fp8e4b15",
                "fp8e5"
            ],
            "target": null,
            "tmem_size": 0,
            "triton_version": "3.3.1"
        }
    }
}