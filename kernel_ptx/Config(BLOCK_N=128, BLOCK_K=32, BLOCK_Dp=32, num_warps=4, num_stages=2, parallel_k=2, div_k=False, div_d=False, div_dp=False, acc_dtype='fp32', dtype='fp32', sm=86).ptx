//
// Generated by LLVM NVPTX Back-End
//

.version 8.2
.target sm_86
.address_size 64

	// .globl	implicit_conv3d_kernel  // -- Begin function implicit_conv3d_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @implicit_conv3d_kernel
.visible .entry implicit_conv3d_kernel(
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_0,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_1,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_2,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_3,
	.param .u32 implicit_conv3d_kernel_param_4,
	.param .u32 implicit_conv3d_kernel_param_5,
	.param .u32 implicit_conv3d_kernel_param_6,
	.param .u32 implicit_conv3d_kernel_param_7,
	.param .u32 implicit_conv3d_kernel_param_8,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_9
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<209>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<1285>;
	.reg .f32 	%f<546>;
	.reg .b64 	%rd<382>;
	.loc	1 33 0                          // implicit_gemm_kernel.py:33:0
$L__func_begin0:
	.loc	1 33 0                          // implicit_gemm_kernel.py:33:0

// %bb.0:
	ld.param.u32 	%r232, [implicit_conv3d_kernel_param_7];
	ld.param.u32 	%r230, [implicit_conv3d_kernel_param_5];
	ld.param.u64 	%rd91, [implicit_conv3d_kernel_param_3];
$L__tmp0:
	.loc	1 49 24                         // implicit_gemm_kernel.py:49:24
	mov.u32 	%r233, %ctaid.x;
	.loc	1 50 36                         // implicit_gemm_kernel.py:50:36
	shr.u32 	%r234, %r233, 31;
	add.s32 	%r235, %r233, %r234;
	and.b32  	%r236, %r235, -2;
	sub.s32 	%r1246, %r233, %r236;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22
	add.s32 	%r237, %r230, 127;
$L__tmp2:
	.loc	1 49 35                         // implicit_gemm_kernel.py:49:35
	shr.s32 	%r238, %r235, 1;
	shr.s32 	%r240, %r237, 31;
	shr.u32 	%r241, %r240, 25;
	add.s32 	%r242, %r237, %r241;
	shr.s32 	%r243, %r242, 7;
	ld.param.u32 	%r244, [implicit_conv3d_kernel_param_8];
	.loc	1 54 20                         // implicit_gemm_kernel.py:54:20
	div.s32 	%r2, %r238, %r243;
	.loc	1 53 18                         // implicit_gemm_kernel.py:53:18
	mul.lo.s32 	%r245, %r2, %r243;
	sub.s32 	%r246, %r238, %r245;
	.loc	1 56 19                         // implicit_gemm_kernel.py:56:19
	mul.lo.s32 	%r247, %r244, %r244;
	.loc	1 56 23                         // implicit_gemm_kernel.py:56:23
	mul.lo.s32 	%r3, %r247, %r244;
	.loc	1 58 38                         // implicit_gemm_kernel.py:58:38
	mov.u32 	%r4, %tid.x;
	and.b32  	%r5, %r4, 31;
	and.b32  	%r6, %r4, 16;
	.loc	1 58 57                         // implicit_gemm_kernel.py:58:57
	shl.b32 	%r8, %r246, 7;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	setp.lt.s32 	%p4, %r1246, %r3;
	mov.u32 	%r1245, global_smem;
	@%p4 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:                              // %.lr.ph13
	.loc	1 0 39                          // implicit_gemm_kernel.py:0:39
	ld.param.u32 	%r231, [implicit_conv3d_kernel_param_6];
	ld.param.u32 	%r229, [implicit_conv3d_kernel_param_4];
	ld.param.u64 	%rd90, [implicit_conv3d_kernel_param_2];
	ld.param.u64 	%rd89, [implicit_conv3d_kernel_param_0];
	ld.param.u64 	%rd92, [implicit_conv3d_kernel_param_1];
	.loc	1 58 0                          // implicit_gemm_kernel.py:58:0
	and.b32  	%r7, %r4, 127;
	or.b32  	%r9, %r8, %r7;
	mul.lo.s32 	%r248, %r9, %r3;
	mul.wide.s32 	%rd93, %r248, 4;
	add.s64 	%rd1, %rd92, %rd93;
	.loc	1 58 38                         // implicit_gemm_kernel.py:58:38
	and.b32  	%r252, %r4, 15;
	and.b32  	%r253, %r4, 4;
	and.b32  	%r254, %r4, 2;
	and.b32  	%r255, %r4, 1;
	shr.u32 	%r1248, %r4, 5;
	bfe.u32 	%r16, %r4, 5, 2;
	shl.b32 	%r256, %r7, 2;
	add.s32 	%r334, %r1245, %r256;
	shl.b32 	%r258, %r16, 2;
	add.s32 	%r18, %r1245, %r258;
	or.b32  	%r19, %r16, 4;
	or.b32  	%r20, %r16, 8;
	or.b32  	%r21, %r16, 12;
	or.b32  	%r22, %r16, 16;
	or.b32  	%r23, %r16, 20;
	or.b32  	%r24, %r16, 24;
	or.b32  	%r25, %r16, 28;
	add.s32 	%r336, %r1245, %r16;
	setp.lt.s32 	%p5, %r4, 4;
	add.s32 	%r337, %r1245, %r4;
	and.b32  	%r259, %r4, 3;
	setp.eq.s32 	%p6, %r259, 0;
	and.pred  	%p14, %p5, %p6;
	add.s32 	%r28, %r231, 31;
	shr.s32 	%r260, %r28, 31;
	shr.u32 	%r261, %r260, 27;
	add.s32 	%r262, %r28, %r261;
	shr.s32 	%r263, %r262, 5;
	shl.b32 	%r264, %r2, 5;
	mul.lo.s32 	%r29, %r3, %r231;
	or.b32  	%r1252, %r264, %r5;
	setp.lt.s32 	%p7, %r1252, %r232;
	setp.gt.s32 	%p8, %r28, 31;
	setp.lt.s32 	%p9, %r5, %r231;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	and.pred  	%p2, %p9, %p8;
	shr.u32 	%r265, %r4, 3;
	and.b32  	%r266, %r265, 12;
	xor.b32  	%r267, %r266, %r5;
	shl.b32 	%r268, %r16, 5;
	or.b32  	%r269, %r267, %r268;
	shl.b32 	%r270, %r269, 2;
	add.s32 	%r349, %r1245, %r270;
	or.b32  	%r271, %r259, 16;
	and.b32  	%r272, %r4, 12;
	or.b32  	%r273, %r272, %r271;
	or.b32  	%r274, %r266, %r6;
	xor.b32  	%r275, %r274, %r273;
	shl.b32 	%r276, %r275, 2;
	add.s32 	%r277, %r1245, %r276;
	shl.b32 	%r278, %r16, 7;
	add.s32 	%r279, %r277, %r278;
	add.s32 	%r351, %r279, 512;
	add.s32 	%r353, %r349, 1024;
	add.s32 	%r355, %r279, 1536;
	add.s32 	%r357, %r349, 2048;
	add.s32 	%r359, %r279, 2560;
	add.s32 	%r361, %r349, 3072;
	add.s32 	%r363, %r279, 3584;
	add.s32 	%r365, %r349, 4096;
	add.s32 	%r367, %r279, 4608;
	add.s32 	%r369, %r349, 5120;
	add.s32 	%r371, %r279, 5632;
	add.s32 	%r373, %r349, 6144;
	add.s32 	%r375, %r279, 6656;
	add.s32 	%r377, %r349, 7168;
	add.s32 	%r379, %r279, 7680;
	add.s32 	%r381, %r349, 8192;
	add.s32 	%r383, %r279, 8704;
	add.s32 	%r385, %r349, 9216;
	add.s32 	%r387, %r279, 9728;
	add.s32 	%r389, %r349, 10240;
	add.s32 	%r391, %r279, 10752;
	add.s32 	%r393, %r349, 11264;
	add.s32 	%r395, %r279, 11776;
	add.s32 	%r397, %r349, 12288;
	add.s32 	%r399, %r279, 12800;
	add.s32 	%r401, %r349, 13312;
	add.s32 	%r403, %r279, 13824;
	add.s32 	%r405, %r349, 14336;
	add.s32 	%r407, %r279, 14848;
	add.s32 	%r409, %r349, 15360;
	add.s32 	%r411, %r279, 15872;
	shr.u32 	%r1251, %r4, 2;
	and.b32  	%r280, %r1251, 24;
	xor.b32  	%r281, %r280, %r5;
	or.b32  	%r282, %r281, %r268;
	shl.b32 	%r283, %r282, 2;
	add.s32 	%r284, %r1245, %r283;
	add.s32 	%r413, %r284, 16384;
	add.s32 	%r415, %r284, 16896;
	add.s32 	%r417, %r284, 17408;
	add.s32 	%r419, %r284, 17920;
	add.s32 	%r421, %r284, 18432;
	add.s32 	%r423, %r284, 18944;
	add.s32 	%r425, %r284, 19456;
	add.s32 	%r427, %r284, 19968;
	add.s32 	%r285, %r263, -1;
	shl.b32 	%r286, %r255, 2;
	shl.b32 	%r287, %r254, 2;
	or.b32  	%r288, %r286, %r287;
	shl.b32 	%r289, %r253, 2;
	or.b32  	%r290, %r288, %r289;
	shr.u32 	%r1250, %r6, 2;
	xor.b32  	%r73, %r290, %r1250;
	shr.u32 	%r291, %r4, 1;
	and.b32  	%r1249, %r291, 48;
	or.b32  	%r292, %r1249, %r252;
	shl.b32 	%r75, %r292, 5;
	or.b32  	%r76, %r73, %r75;
	or.b32  	%r293, %r286, 8;
	xor.b32  	%r294, %r293, %r287;
	or.b32  	%r295, %r294, %r289;
	xor.b32  	%r77, %r295, %r1250;
	or.b32  	%r78, %r77, %r75;
	or.b32  	%r296, %r288, 16;
	or.b32  	%r297, %r1250, %r289;
	xor.b32  	%r79, %r297, %r296;
	or.b32  	%r80, %r79, %r75;
	or.b32  	%r298, %r286, 24;
	or.b32  	%r299, %r297, %r287;
	xor.b32  	%r81, %r299, %r298;
	or.b32  	%r82, %r81, %r75;
	shl.b32 	%r300, %r255, 3;
	shl.b32 	%r301, %r254, 3;
	bfe.u32 	%r302, %r4, 2, 1;
	and.b32  	%r303, %r1251, 2;
	or.b32  	%r304, %r303, %r302;
	or.b32  	%r305, %r304, %r301;
	or.b32  	%r306, %r305, %r300;
	or.b32  	%r83, %r306, %r1250;
	shl.b32 	%r307, %r4, 5;
	and.b32  	%r84, %r307, 96;
	or.b32  	%r85, %r83, %r84;
	shl.b32 	%r86, %r271, 5;
	or.b32  	%r87, %r83, %r86;
	xor.b32  	%r88, %r83, 8;
	or.b32  	%r308, %r300, 16;
	xor.b32  	%r309, %r308, %r301;
	or.b32  	%r310, %r302, %r309;
	or.b32  	%r311, %r310, %r303;
	or.b32  	%r89, %r311, %r1250;
	xor.b32  	%r90, %r83, 24;
	cvt.s64.s32 	%rd2, %r285;
	cvt.u64.u32 	%rd3, %r5;
	cvt.s64.s32 	%rd4, %r231;
	cvt.u64.u32 	%rd5, %r263;
	and.pred  	%p3, %p7, %p8;
	or.b64  	%rd6, %rd3, 32;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	or.b32  	%r91, %r5, 32;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	mad.lo.s32 	%r312, %r1246, %r231, %r16;
	cvt.u64.u32 	%rd371, %r312;
	shl.b32 	%r313, %r231, 1;
	cvt.u64.u32 	%rd8, %r313;
	add.s32 	%r314, %r312, 60;
	mad.lo.s32 	%r315, %r232, %r314, %r264;
	cvt.u64.u32 	%rd370, %r315;
	mul.lo.s32 	%r316, %r232, %r231;
	shl.b32 	%r317, %r316, 1;
	cvt.u64.u32 	%rd10, %r317;
	shl.b32 	%r318, %r232, 5;
	cvt.u64.u32 	%rd11, %r318;
	add.s32 	%r319, %r312, 56;
	mad.lo.s32 	%r320, %r232, %r319, %r264;
	cvt.u64.u32 	%rd369, %r320;
	add.s32 	%r321, %r312, 52;
	mad.lo.s32 	%r322, %r232, %r321, %r264;
	cvt.u64.u32 	%rd368, %r322;
	add.s32 	%r323, %r312, 48;
	mad.lo.s32 	%r324, %r232, %r323, %r264;
	cvt.u64.u32 	%rd367, %r324;
	add.s32 	%r325, %r312, 44;
	mad.lo.s32 	%r326, %r232, %r325, %r264;
	cvt.u64.u32 	%rd366, %r326;
	add.s32 	%r327, %r312, 40;
	mad.lo.s32 	%r328, %r232, %r327, %r264;
	cvt.u64.u32 	%rd365, %r328;
	add.s32 	%r329, %r312, 36;
	mad.lo.s32 	%r330, %r232, %r329, %r264;
	cvt.u64.u32 	%rd364, %r330;
	add.s32 	%r331, %r312, 32;
	mad.lo.s32 	%r332, %r232, %r331, %r264;
	cvt.u64.u32 	%rd363, %r332;
	mov.f32 	%f450, 0f00000000;
	shl.b32 	%r829, %r76, 2;
	shl.b32 	%r830, %r78, 2;
	shl.b32 	%r831, %r80, 2;
	shl.b32 	%r832, %r82, 2;
	shl.b32 	%r848, %r85, 2;
	shl.b32 	%r853, %r87, 2;
	shl.b32 	%r855, %r88, 2;
	shl.b32 	%r861, %r89, 2;
	shl.b32 	%r865, %r90, 2;
	mov.f32 	%f451, %f450;
	mov.f32 	%f452, %f450;
	mov.f32 	%f453, %f450;
	mov.f32 	%f454, %f450;
	mov.f32 	%f455, %f450;
	mov.f32 	%f456, %f450;
	mov.f32 	%f457, %f450;
	mov.f32 	%f458, %f450;
	mov.f32 	%f459, %f450;
	mov.f32 	%f460, %f450;
	mov.f32 	%f461, %f450;
	mov.f32 	%f462, %f450;
	mov.f32 	%f463, %f450;
	mov.f32 	%f464, %f450;
	mov.f32 	%f465, %f450;
	mov.f32 	%f466, %f450;
	mov.f32 	%f467, %f450;
	mov.f32 	%f468, %f450;
	mov.f32 	%f469, %f450;
	mov.f32 	%f470, %f450;
	mov.f32 	%f471, %f450;
	mov.f32 	%f472, %f450;
	mov.f32 	%f473, %f450;
	mov.f32 	%f474, %f450;
	mov.f32 	%f475, %f450;
	mov.f32 	%f476, %f450;
	mov.f32 	%f477, %f450;
	mov.f32 	%f478, %f450;
	mov.f32 	%f479, %f450;
	mov.f32 	%f480, %f450;
	mov.f32 	%f481, %f450;
	bra.uni 	$L__BB0_3;
$L__BB0_7:                              // %._crit_edge
                                        //   in Loop: Header=BB0_3 Depth=1
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	cp.async.wait_group 0;
	bar.sync 	0;
$L__BB0_8:                              //   in Loop: Header=BB0_3 Depth=1
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	add.s32 	%r1246, %r1246, 2;
	add.s64 	%rd371, %rd371, %rd8;
	add.s64 	%rd370, %rd370, %rd10;
	add.s64 	%rd369, %rd369, %rd10;
	add.s64 	%rd368, %rd368, %rd10;
	add.s64 	%rd367, %rd367, %rd10;
	add.s64 	%rd366, %rd366, %rd10;
	add.s64 	%rd365, %rd365, %rd10;
	add.s64 	%rd364, %rd364, %rd10;
	add.s64 	%rd363, %rd363, %rd10;
	setp.lt.s32 	%p111, %r1246, %r3;
	@%p111 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_9;
$L__BB0_3:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_6 Depth 2
	.loc	1 0 39                          // implicit_gemm_kernel.py:0:39
	setp.eq.s32 	%p12, %r5, 0;
	.loc	1 63 85                         // implicit_gemm_kernel.py:63:85
	setp.lt.s32 	%p10, %r9, %r230;
	.loc	1 63 33                         // implicit_gemm_kernel.py:63:33
	mul.wide.s32 	%rd95, %r1246, 4;
	add.s64 	%rd94, %rd1, %rd95;
	.loc	1 63 23                         // implicit_gemm_kernel.py:63:23
	// begin inline asm
	mov.u32 %r335, 0xffffffffffffffff;
	@%p10 ld.global.b32 { %r335 }, [ %rd94 + 0 ];
	// end inline asm
	.loc	1 69 56                         // implicit_gemm_kernel.py:69:56
	bar.sync 	0;
	mov.pred 	%p11, -1;
	// begin inline asm
	@%p11 st.shared.b32 [ %r334 + 0 ], %r335;
	// end inline asm
	bar.sync 	0;
	ld.shared.u32 	%r93, [%r18];
	ld.shared.u32 	%r94, [%r18+16];
	ld.shared.u32 	%r95, [%r18+32];
	ld.shared.u32 	%r96, [%r18+48];
	ld.shared.u32 	%r97, [%r18+64];
	ld.shared.u32 	%r98, [%r18+80];
	ld.shared.u32 	%r99, [%r18+96];
	ld.shared.u32 	%r100, [%r18+112];
	ld.shared.u32 	%r101, [%r18+128];
	ld.shared.u32 	%r102, [%r18+144];
	ld.shared.u32 	%r103, [%r18+160];
	ld.shared.u32 	%r104, [%r18+176];
	ld.shared.u32 	%r105, [%r18+192];
	ld.shared.u32 	%r106, [%r18+208];
	ld.shared.u32 	%r107, [%r18+224];
	ld.shared.u32 	%r108, [%r18+240];
	ld.shared.u32 	%r109, [%r18+256];
	ld.shared.u32 	%r110, [%r18+272];
	ld.shared.u32 	%r111, [%r18+288];
	ld.shared.u32 	%r112, [%r18+304];
	ld.shared.u32 	%r113, [%r18+320];
	ld.shared.u32 	%r114, [%r18+336];
	ld.shared.u32 	%r115, [%r18+352];
	ld.shared.u32 	%r116, [%r18+368];
	ld.shared.u32 	%r117, [%r18+384];
	ld.shared.u32 	%r118, [%r18+400];
	ld.shared.u32 	%r119, [%r18+416];
	ld.shared.u32 	%r120, [%r18+432];
	ld.shared.u32 	%r121, [%r18+448];
	ld.shared.u32 	%r122, [%r18+464];
	ld.shared.u32 	%r123, [%r18+480];
	ld.shared.u32 	%r124, [%r18+496];
	.loc	1 65 27                         // implicit_gemm_kernel.py:65:27
	setp.gt.s32 	%p15, %r335, -1;
	.loc	1 65 43                         // implicit_gemm_kernel.py:65:43
	setp.lt.s32 	%p16, %r335, %r229;
	.loc	1 65 36                         // implicit_gemm_kernel.py:65:36
	and.pred  	%p17, %p15, %p16;
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	bar.sync 	0;
	selp.u32 	%r339, 1, 0, %p17;
	mov.b32 	%r340, -1;
	redux.sync.or.b32 %r341, %r339, %r340;
	cvt.u16.u32 	%rs4, %r341;
	and.b16  	%rs1, %rs4, 1;
	// begin inline asm
	@%p12 st.shared.b8 [ %r336 + 0 ], %rs1;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p5 ld.shared.b8 %rs2, [ %r337 + 0 ];
	// end inline asm
	cvt.u32.u16 	%r342, %rs2;
	and.b16  	%rs5, %rs2, 1;
	setp.eq.b16 	%p18, %rs5, 1;
	and.b32  	%r343, %r342, 1;
	shfl.sync.bfly.b32	%r344, %r343, 2, 31, -1;
	and.b32  	%r345, %r344, 1;
	setp.eq.b32 	%p19, %r345, 1;
$L__tmp3:
	.loc	1 6 15                          // implicit_gemm_kernel.py:6:15
	or.pred  	%p20, %p18, %p19;
$L__tmp4:
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	selp.u32 	%r346, 1, 0, %p20;
	shfl.sync.bfly.b32	%r347, %r346, 1, 31, -1;
	and.b32  	%r348, %r347, 1;
	setp.eq.b32 	%p21, %r348, 1;
$L__tmp5:
	.loc	1 6 15                          // implicit_gemm_kernel.py:6:15
	or.pred  	%p22, %p20, %p21;
$L__tmp6:
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	selp.u16 	%rs3, 1, 0, %p22;
	// begin inline asm
	@%p14 st.shared.b8 [ %r337 + 0 ], %rs3;
	// end inline asm
	bar.sync 	0;
	ld.shared.u8 	%rs6, [global_smem];
	and.b16  	%rs7, %rs6, 1;
	setp.eq.b16 	%p23, %rs7, 1;
	.loc	1 65 11                         // implicit_gemm_kernel.py:65:11
	not.pred 	%p24, %p23;
	@%p24 bra 	$L__BB0_8;
// %bb.4:                               //   in Loop: Header=BB0_3 Depth=1
	.loc	1 0 11                          // implicit_gemm_kernel.py:0:11
	setp.lt.s32 	%p25, %r28, 32;
	.loc	1 67 31                         // implicit_gemm_kernel.py:67:31
	mul.lo.s32 	%r429, %r1246, %r231;
	.loc	1 69 52                         // implicit_gemm_kernel.py:69:52
	mul.lo.s32 	%r125, %r93, %r231;
	mul.lo.s32 	%r126, %r94, %r231;
	mul.lo.s32 	%r127, %r95, %r231;
	mul.lo.s32 	%r128, %r96, %r231;
	mul.lo.s32 	%r129, %r97, %r231;
	mul.lo.s32 	%r130, %r98, %r231;
	mul.lo.s32 	%r131, %r99, %r231;
	mul.lo.s32 	%r132, %r100, %r231;
	mul.lo.s32 	%r133, %r101, %r231;
	mul.lo.s32 	%r134, %r102, %r231;
	mul.lo.s32 	%r135, %r103, %r231;
	mul.lo.s32 	%r136, %r104, %r231;
	mul.lo.s32 	%r137, %r105, %r231;
	mul.lo.s32 	%r138, %r106, %r231;
	mul.lo.s32 	%r139, %r107, %r231;
	mul.lo.s32 	%r140, %r108, %r231;
	mul.lo.s32 	%r141, %r109, %r231;
	mul.lo.s32 	%r142, %r110, %r231;
	mul.lo.s32 	%r143, %r111, %r231;
	mul.lo.s32 	%r144, %r112, %r231;
	mul.lo.s32 	%r145, %r113, %r231;
	mul.lo.s32 	%r146, %r114, %r231;
	mul.lo.s32 	%r147, %r115, %r231;
	mul.lo.s32 	%r148, %r116, %r231;
	mul.lo.s32 	%r149, %r117, %r231;
	mul.lo.s32 	%r150, %r118, %r231;
	mul.lo.s32 	%r151, %r119, %r231;
	mul.lo.s32 	%r152, %r120, %r231;
	mul.lo.s32 	%r153, %r121, %r231;
	mul.lo.s32 	%r154, %r122, %r231;
	mul.lo.s32 	%r155, %r123, %r231;
	mul.lo.s32 	%r156, %r124, %r231;
	.loc	1 69 56                         // implicit_gemm_kernel.py:69:56
	add.s32 	%r430, %r125, %r5;
	add.s32 	%r431, %r126, %r5;
	add.s32 	%r432, %r127, %r5;
	add.s32 	%r433, %r128, %r5;
	add.s32 	%r434, %r129, %r5;
	add.s32 	%r435, %r130, %r5;
	add.s32 	%r436, %r131, %r5;
	add.s32 	%r437, %r132, %r5;
	add.s32 	%r438, %r133, %r5;
	add.s32 	%r439, %r134, %r5;
	add.s32 	%r440, %r135, %r5;
	add.s32 	%r441, %r136, %r5;
	add.s32 	%r442, %r137, %r5;
	add.s32 	%r443, %r138, %r5;
	add.s32 	%r444, %r139, %r5;
	add.s32 	%r445, %r140, %r5;
	add.s32 	%r446, %r141, %r5;
	add.s32 	%r447, %r142, %r5;
	add.s32 	%r448, %r143, %r5;
	add.s32 	%r449, %r144, %r5;
	add.s32 	%r450, %r145, %r5;
	add.s32 	%r451, %r146, %r5;
	add.s32 	%r452, %r147, %r5;
	add.s32 	%r453, %r148, %r5;
	add.s32 	%r454, %r149, %r5;
	add.s32 	%r455, %r150, %r5;
	add.s32 	%r456, %r151, %r5;
	add.s32 	%r457, %r152, %r5;
	add.s32 	%r458, %r153, %r5;
	add.s32 	%r459, %r154, %r5;
	add.s32 	%r460, %r155, %r5;
	add.s32 	%r461, %r156, %r5;
	.loc	1 70 43                         // implicit_gemm_kernel.py:70:43
	setp.ne.s32 	%p26, %r93, -1;
	setp.ne.s32 	%p27, %r94, -1;
	setp.ne.s32 	%p28, %r95, -1;
	setp.ne.s32 	%p29, %r96, -1;
	setp.ne.s32 	%p30, %r97, -1;
	setp.ne.s32 	%p31, %r98, -1;
	setp.ne.s32 	%p32, %r99, -1;
	setp.ne.s32 	%p33, %r100, -1;
	setp.ne.s32 	%p34, %r101, -1;
	setp.ne.s32 	%p35, %r102, -1;
	setp.ne.s32 	%p36, %r103, -1;
	setp.ne.s32 	%p37, %r104, -1;
	setp.ne.s32 	%p38, %r105, -1;
	setp.ne.s32 	%p39, %r106, -1;
	setp.ne.s32 	%p40, %r107, -1;
	setp.ne.s32 	%p41, %r108, -1;
	setp.ne.s32 	%p42, %r109, -1;
	setp.ne.s32 	%p43, %r110, -1;
	setp.ne.s32 	%p44, %r111, -1;
	setp.ne.s32 	%p45, %r112, -1;
	setp.ne.s32 	%p46, %r113, -1;
	setp.ne.s32 	%p47, %r114, -1;
	setp.ne.s32 	%p48, %r115, -1;
	setp.ne.s32 	%p49, %r116, -1;
	setp.ne.s32 	%p50, %r117, -1;
	setp.ne.s32 	%p51, %r118, -1;
	setp.ne.s32 	%p52, %r119, -1;
	setp.ne.s32 	%p53, %r120, -1;
	setp.ne.s32 	%p54, %r121, -1;
	setp.ne.s32 	%p55, %r122, -1;
	setp.ne.s32 	%p56, %r123, -1;
	setp.ne.s32 	%p57, %r124, -1;
	.loc	1 69 36                         // implicit_gemm_kernel.py:69:36
	mul.wide.s32 	%rd136, %r430, 4;
	add.s64 	%rd96, %rd89, %rd136;
	mul.wide.s32 	%rd137, %r431, 4;
	add.s64 	%rd97, %rd89, %rd137;
	mul.wide.s32 	%rd138, %r432, 4;
	add.s64 	%rd98, %rd89, %rd138;
	mul.wide.s32 	%rd139, %r433, 4;
	add.s64 	%rd99, %rd89, %rd139;
	mul.wide.s32 	%rd140, %r434, 4;
	add.s64 	%rd100, %rd89, %rd140;
	mul.wide.s32 	%rd141, %r435, 4;
	add.s64 	%rd101, %rd89, %rd141;
	mul.wide.s32 	%rd142, %r436, 4;
	add.s64 	%rd102, %rd89, %rd142;
	mul.wide.s32 	%rd143, %r437, 4;
	add.s64 	%rd103, %rd89, %rd143;
	mul.wide.s32 	%rd144, %r438, 4;
	add.s64 	%rd104, %rd89, %rd144;
	mul.wide.s32 	%rd145, %r439, 4;
	add.s64 	%rd105, %rd89, %rd145;
	mul.wide.s32 	%rd146, %r440, 4;
	add.s64 	%rd106, %rd89, %rd146;
	mul.wide.s32 	%rd147, %r441, 4;
	add.s64 	%rd107, %rd89, %rd147;
	mul.wide.s32 	%rd148, %r442, 4;
	add.s64 	%rd108, %rd89, %rd148;
	mul.wide.s32 	%rd149, %r443, 4;
	add.s64 	%rd109, %rd89, %rd149;
	mul.wide.s32 	%rd150, %r444, 4;
	add.s64 	%rd110, %rd89, %rd150;
	mul.wide.s32 	%rd151, %r445, 4;
	add.s64 	%rd111, %rd89, %rd151;
	mul.wide.s32 	%rd152, %r446, 4;
	add.s64 	%rd112, %rd89, %rd152;
	mul.wide.s32 	%rd153, %r447, 4;
	add.s64 	%rd113, %rd89, %rd153;
	mul.wide.s32 	%rd154, %r448, 4;
	add.s64 	%rd114, %rd89, %rd154;
	mul.wide.s32 	%rd155, %r449, 4;
	add.s64 	%rd115, %rd89, %rd155;
	mul.wide.s32 	%rd156, %r450, 4;
	add.s64 	%rd116, %rd89, %rd156;
	mul.wide.s32 	%rd157, %r451, 4;
	add.s64 	%rd117, %rd89, %rd157;
	mul.wide.s32 	%rd158, %r452, 4;
	add.s64 	%rd118, %rd89, %rd158;
	mul.wide.s32 	%rd159, %r453, 4;
	add.s64 	%rd119, %rd89, %rd159;
	mul.wide.s32 	%rd160, %r454, 4;
	add.s64 	%rd120, %rd89, %rd160;
	mul.wide.s32 	%rd161, %r455, 4;
	add.s64 	%rd121, %rd89, %rd161;
	mul.wide.s32 	%rd162, %r456, 4;
	add.s64 	%rd122, %rd89, %rd162;
	mul.wide.s32 	%rd163, %r457, 4;
	add.s64 	%rd123, %rd89, %rd163;
	mul.wide.s32 	%rd164, %r458, 4;
	add.s64 	%rd124, %rd89, %rd164;
	mul.wide.s32 	%rd165, %r459, 4;
	add.s64 	%rd125, %rd89, %rd165;
	mul.wide.s32 	%rd166, %r460, 4;
	add.s64 	%rd126, %rd89, %rd166;
	mul.wide.s32 	%rd167, %r461, 4;
	add.s64 	%rd127, %rd89, %rd167;
	.loc	1 73 54                         // implicit_gemm_kernel.py:73:54
	add.s32 	%r462, %r429, %r16;
	add.s32 	%r463, %r429, %r19;
	add.s32 	%r464, %r429, %r20;
	add.s32 	%r465, %r429, %r21;
	add.s32 	%r466, %r429, %r22;
	add.s32 	%r467, %r429, %r23;
	add.s32 	%r468, %r429, %r24;
	add.s32 	%r469, %r429, %r25;
	.loc	1 75 22                         // implicit_gemm_kernel.py:75:22
	mad.lo.s32 	%r470, %r462, %r232, %r1252;
	mad.lo.s32 	%r471, %r463, %r232, %r1252;
	mad.lo.s32 	%r472, %r464, %r232, %r1252;
	mad.lo.s32 	%r473, %r465, %r232, %r1252;
	mad.lo.s32 	%r474, %r466, %r232, %r1252;
	mad.lo.s32 	%r475, %r467, %r232, %r1252;
	mad.lo.s32 	%r476, %r468, %r232, %r1252;
	mad.lo.s32 	%r477, %r469, %r232, %r1252;
	.loc	1 73 20                         // implicit_gemm_kernel.py:73:20
	mul.wide.s32 	%rd168, %r470, 4;
	add.s64 	%rd128, %rd90, %rd168;
	mul.wide.s32 	%rd169, %r471, 4;
	add.s64 	%rd129, %rd90, %rd169;
	mul.wide.s32 	%rd170, %r472, 4;
	add.s64 	%rd130, %rd90, %rd170;
	mul.wide.s32 	%rd171, %r473, 4;
	add.s64 	%rd131, %rd90, %rd171;
	mul.wide.s32 	%rd172, %r474, 4;
	add.s64 	%rd132, %rd90, %rd172;
	mul.wide.s32 	%rd173, %r475, 4;
	add.s64 	%rd133, %rd90, %rd173;
	mul.wide.s32 	%rd174, %r476, 4;
	add.s64 	%rd134, %rd90, %rd174;
	mul.wide.s32 	%rd175, %r477, 4;
	add.s64 	%rd135, %rd90, %rd175;
	.loc	1 77 72                         // implicit_gemm_kernel.py:77:72
	setp.lt.s32 	%p58, %r462, %r29;
	setp.lt.s32 	%p59, %r463, %r29;
	setp.lt.s32 	%p60, %r464, %r29;
	setp.lt.s32 	%p61, %r465, %r29;
	setp.lt.s32 	%p62, %r466, %r29;
	setp.lt.s32 	%p63, %r467, %r29;
	setp.lt.s32 	%p64, %r468, %r29;
	setp.lt.s32 	%p65, %r469, %r29;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	bar.sync 	0;
	selp.b32 	%r478, 4, 0, %p2;
	selp.b32 	%r350, %r478, 0, %p26;
	// begin inline asm
	cp.async.ca.shared.global [ %r349 + 0 ], [ %rd96 + 0 ], 0x4, %r350;
	// end inline asm
	selp.b32 	%r352, %r478, 0, %p27;
	// begin inline asm
	cp.async.ca.shared.global [ %r351 + 0 ], [ %rd97 + 0 ], 0x4, %r352;
	// end inline asm
	selp.b32 	%r354, %r478, 0, %p28;
	// begin inline asm
	cp.async.ca.shared.global [ %r353 + 0 ], [ %rd98 + 0 ], 0x4, %r354;
	// end inline asm
	selp.b32 	%r356, %r478, 0, %p29;
	// begin inline asm
	cp.async.ca.shared.global [ %r355 + 0 ], [ %rd99 + 0 ], 0x4, %r356;
	// end inline asm
	selp.b32 	%r358, %r478, 0, %p30;
	// begin inline asm
	cp.async.ca.shared.global [ %r357 + 0 ], [ %rd100 + 0 ], 0x4, %r358;
	// end inline asm
	selp.b32 	%r360, %r478, 0, %p31;
	// begin inline asm
	cp.async.ca.shared.global [ %r359 + 0 ], [ %rd101 + 0 ], 0x4, %r360;
	// end inline asm
	selp.b32 	%r362, %r478, 0, %p32;
	// begin inline asm
	cp.async.ca.shared.global [ %r361 + 0 ], [ %rd102 + 0 ], 0x4, %r362;
	// end inline asm
	selp.b32 	%r364, %r478, 0, %p33;
	// begin inline asm
	cp.async.ca.shared.global [ %r363 + 0 ], [ %rd103 + 0 ], 0x4, %r364;
	// end inline asm
	selp.b32 	%r366, %r478, 0, %p34;
	// begin inline asm
	cp.async.ca.shared.global [ %r365 + 0 ], [ %rd104 + 0 ], 0x4, %r366;
	// end inline asm
	selp.b32 	%r368, %r478, 0, %p35;
	// begin inline asm
	cp.async.ca.shared.global [ %r367 + 0 ], [ %rd105 + 0 ], 0x4, %r368;
	// end inline asm
	selp.b32 	%r370, %r478, 0, %p36;
	// begin inline asm
	cp.async.ca.shared.global [ %r369 + 0 ], [ %rd106 + 0 ], 0x4, %r370;
	// end inline asm
	selp.b32 	%r372, %r478, 0, %p37;
	// begin inline asm
	cp.async.ca.shared.global [ %r371 + 0 ], [ %rd107 + 0 ], 0x4, %r372;
	// end inline asm
	selp.b32 	%r374, %r478, 0, %p38;
	// begin inline asm
	cp.async.ca.shared.global [ %r373 + 0 ], [ %rd108 + 0 ], 0x4, %r374;
	// end inline asm
	selp.b32 	%r376, %r478, 0, %p39;
	// begin inline asm
	cp.async.ca.shared.global [ %r375 + 0 ], [ %rd109 + 0 ], 0x4, %r376;
	// end inline asm
	selp.b32 	%r378, %r478, 0, %p40;
	// begin inline asm
	cp.async.ca.shared.global [ %r377 + 0 ], [ %rd110 + 0 ], 0x4, %r378;
	// end inline asm
	selp.b32 	%r380, %r478, 0, %p41;
	// begin inline asm
	cp.async.ca.shared.global [ %r379 + 0 ], [ %rd111 + 0 ], 0x4, %r380;
	// end inline asm
	selp.b32 	%r382, %r478, 0, %p42;
	// begin inline asm
	cp.async.ca.shared.global [ %r381 + 0 ], [ %rd112 + 0 ], 0x4, %r382;
	// end inline asm
	selp.b32 	%r384, %r478, 0, %p43;
	// begin inline asm
	cp.async.ca.shared.global [ %r383 + 0 ], [ %rd113 + 0 ], 0x4, %r384;
	// end inline asm
	selp.b32 	%r386, %r478, 0, %p44;
	// begin inline asm
	cp.async.ca.shared.global [ %r385 + 0 ], [ %rd114 + 0 ], 0x4, %r386;
	// end inline asm
	selp.b32 	%r388, %r478, 0, %p45;
	// begin inline asm
	cp.async.ca.shared.global [ %r387 + 0 ], [ %rd115 + 0 ], 0x4, %r388;
	// end inline asm
	selp.b32 	%r390, %r478, 0, %p46;
	// begin inline asm
	cp.async.ca.shared.global [ %r389 + 0 ], [ %rd116 + 0 ], 0x4, %r390;
	// end inline asm
	selp.b32 	%r392, %r478, 0, %p47;
	// begin inline asm
	cp.async.ca.shared.global [ %r391 + 0 ], [ %rd117 + 0 ], 0x4, %r392;
	// end inline asm
	selp.b32 	%r394, %r478, 0, %p48;
	// begin inline asm
	cp.async.ca.shared.global [ %r393 + 0 ], [ %rd118 + 0 ], 0x4, %r394;
	// end inline asm
	selp.b32 	%r396, %r478, 0, %p49;
	// begin inline asm
	cp.async.ca.shared.global [ %r395 + 0 ], [ %rd119 + 0 ], 0x4, %r396;
	// end inline asm
	selp.b32 	%r398, %r478, 0, %p50;
	// begin inline asm
	cp.async.ca.shared.global [ %r397 + 0 ], [ %rd120 + 0 ], 0x4, %r398;
	// end inline asm
	selp.b32 	%r400, %r478, 0, %p51;
	// begin inline asm
	cp.async.ca.shared.global [ %r399 + 0 ], [ %rd121 + 0 ], 0x4, %r400;
	// end inline asm
	selp.b32 	%r402, %r478, 0, %p52;
	// begin inline asm
	cp.async.ca.shared.global [ %r401 + 0 ], [ %rd122 + 0 ], 0x4, %r402;
	// end inline asm
	selp.b32 	%r404, %r478, 0, %p53;
	// begin inline asm
	cp.async.ca.shared.global [ %r403 + 0 ], [ %rd123 + 0 ], 0x4, %r404;
	// end inline asm
	selp.b32 	%r406, %r478, 0, %p54;
	// begin inline asm
	cp.async.ca.shared.global [ %r405 + 0 ], [ %rd124 + 0 ], 0x4, %r406;
	// end inline asm
	selp.b32 	%r408, %r478, 0, %p55;
	// begin inline asm
	cp.async.ca.shared.global [ %r407 + 0 ], [ %rd125 + 0 ], 0x4, %r408;
	// end inline asm
	selp.b32 	%r410, %r478, 0, %p56;
	// begin inline asm
	cp.async.ca.shared.global [ %r409 + 0 ], [ %rd126 + 0 ], 0x4, %r410;
	// end inline asm
	selp.b32 	%r412, %r478, 0, %p57;
	// begin inline asm
	cp.async.ca.shared.global [ %r411 + 0 ], [ %rd127 + 0 ], 0x4, %r412;
	// end inline asm
	cp.async.commit_group;
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	selp.b32 	%r479, 4, 0, %p3;
	selp.b32 	%r414, %r479, 0, %p58;
	// begin inline asm
	cp.async.ca.shared.global [ %r413 + 0 ], [ %rd128 + 0 ], 0x4, %r414;
	// end inline asm
	selp.b32 	%r416, %r479, 0, %p59;
	// begin inline asm
	cp.async.ca.shared.global [ %r415 + 0 ], [ %rd129 + 0 ], 0x4, %r416;
	// end inline asm
	selp.b32 	%r418, %r479, 0, %p60;
	// begin inline asm
	cp.async.ca.shared.global [ %r417 + 0 ], [ %rd130 + 0 ], 0x4, %r418;
	// end inline asm
	selp.b32 	%r420, %r479, 0, %p61;
	// begin inline asm
	cp.async.ca.shared.global [ %r419 + 0 ], [ %rd131 + 0 ], 0x4, %r420;
	// end inline asm
	selp.b32 	%r422, %r479, 0, %p62;
	// begin inline asm
	cp.async.ca.shared.global [ %r421 + 0 ], [ %rd132 + 0 ], 0x4, %r422;
	// end inline asm
	selp.b32 	%r424, %r479, 0, %p63;
	// begin inline asm
	cp.async.ca.shared.global [ %r423 + 0 ], [ %rd133 + 0 ], 0x4, %r424;
	// end inline asm
	selp.b32 	%r426, %r479, 0, %p64;
	// begin inline asm
	cp.async.ca.shared.global [ %r425 + 0 ], [ %rd134 + 0 ], 0x4, %r426;
	// end inline asm
	selp.b32 	%r428, %r479, 0, %p65;
	// begin inline asm
	cp.async.ca.shared.global [ %r427 + 0 ], [ %rd135 + 0 ], 0x4, %r428;
	// end inline asm
	cp.async.commit_group;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	@%p25 bra 	$L__BB0_7;
// %bb.5:                               // %.lr.ph.preheader
                                        //   in Loop: Header=BB0_3 Depth=1
	add.s32 	%r481, %r91, %r156;
	cvt.u64.u32 	%rd28, %r481;
	add.s32 	%r482, %r91, %r155;
	cvt.u64.u32 	%rd29, %r482;
	add.s32 	%r483, %r91, %r154;
	cvt.u64.u32 	%rd30, %r483;
	add.s32 	%r484, %r91, %r153;
	cvt.u64.u32 	%rd31, %r484;
	add.s32 	%r485, %r91, %r152;
	cvt.u64.u32 	%rd32, %r485;
	add.s32 	%r486, %r91, %r151;
	cvt.u64.u32 	%rd33, %r486;
	add.s32 	%r487, %r91, %r150;
	cvt.u64.u32 	%rd34, %r487;
	add.s32 	%r488, %r91, %r149;
	cvt.u64.u32 	%rd35, %r488;
	add.s32 	%r489, %r91, %r148;
	cvt.u64.u32 	%rd36, %r489;
	add.s32 	%r490, %r91, %r147;
	cvt.u64.u32 	%rd37, %r490;
	add.s32 	%r491, %r91, %r146;
	cvt.u64.u32 	%rd38, %r491;
	add.s32 	%r492, %r91, %r145;
	cvt.u64.u32 	%rd39, %r492;
	add.s32 	%r493, %r91, %r144;
	cvt.u64.u32 	%rd40, %r493;
	add.s32 	%r494, %r91, %r143;
	cvt.u64.u32 	%rd41, %r494;
	add.s32 	%r495, %r91, %r142;
	cvt.u64.u32 	%rd42, %r495;
	add.s32 	%r496, %r91, %r141;
	cvt.u64.u32 	%rd43, %r496;
	add.s32 	%r497, %r91, %r140;
	cvt.u64.u32 	%rd44, %r497;
	add.s32 	%r498, %r91, %r139;
	cvt.u64.u32 	%rd45, %r498;
	add.s32 	%r499, %r91, %r138;
	cvt.u64.u32 	%rd46, %r499;
	add.s32 	%r500, %r91, %r137;
	cvt.u64.u32 	%rd47, %r500;
	add.s32 	%r501, %r91, %r136;
	cvt.u64.u32 	%rd48, %r501;
	add.s32 	%r502, %r91, %r135;
	cvt.u64.u32 	%rd49, %r502;
	add.s32 	%r503, %r91, %r134;
	cvt.u64.u32 	%rd50, %r503;
	add.s32 	%r504, %r91, %r133;
	cvt.u64.u32 	%rd51, %r504;
	add.s32 	%r505, %r91, %r132;
	cvt.u64.u32 	%rd52, %r505;
	add.s32 	%r506, %r91, %r131;
	cvt.u64.u32 	%rd53, %r506;
	add.s32 	%r507, %r91, %r130;
	cvt.u64.u32 	%rd54, %r507;
	add.s32 	%r508, %r91, %r129;
	cvt.u64.u32 	%rd55, %r508;
	add.s32 	%r509, %r91, %r128;
	cvt.u64.u32 	%rd56, %r509;
	add.s32 	%r510, %r91, %r127;
	cvt.u64.u32 	%rd57, %r510;
	add.s32 	%r511, %r91, %r126;
	cvt.u64.u32 	%rd58, %r511;
	add.s32 	%r512, %r91, %r125;
	cvt.u64.u32 	%rd59, %r512;
	mov.b32 	%r1247, -1;
	mov.b64 	%rd380, 0;
	mov.u64 	%rd372, %rd363;
	mov.u64 	%rd373, %rd364;
	mov.u64 	%rd374, %rd365;
	mov.u64 	%rd375, %rd366;
	mov.u64 	%rd376, %rd367;
	mov.u64 	%rd377, %rd368;
	mov.u64 	%rd378, %rd369;
	mov.u64 	%rd379, %rd370;
	mov.u64 	%rd381, %rd380;
$L__BB0_6:                              // %.lr.ph
                                        //   Parent Loop BB0_3 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	setp.lt.s64 	%p99, %rd381, %rd2;
	add.s32 	%r825, %r1247, 1;
	setp.gt.u32 	%p100, %r1247, 2147483646;
	selp.b32 	%r1247, %r825, 0, %p100;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	cp.async.wait_group 0;
	bar.sync 	0;
	shl.b32 	%r826, %r1247, 14;
	add.s32 	%r828, %r1245, %r826;
	add.s32 	%r517, %r828, %r829;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r553, %r554, %r555, %r556}, [%r517];
	// end inline asm
	add.s32 	%r522, %r828, %r830;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r601, %r602, %r603, %r604}, [%r522];
	// end inline asm
	add.s32 	%r527, %r828, %r831;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r649, %r650, %r651, %r652}, [%r527];
	// end inline asm
	add.s32 	%r532, %r828, %r832;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r697, %r698, %r699, %r700}, [%r532];
	// end inline asm
	add.s32 	%r833, %r73, %r75;
	shl.b32 	%r834, %r833, 2;
	add.s32 	%r835, %r828, %r834;
	add.s32 	%r537, %r835, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r577, %r578, %r579, %r580}, [%r537];
	// end inline asm
	add.s32 	%r836, %r77, %r75;
	shl.b32 	%r837, %r836, 2;
	add.s32 	%r838, %r828, %r837;
	add.s32 	%r542, %r838, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r625, %r626, %r627, %r628}, [%r542];
	// end inline asm
	add.s32 	%r839, %r79, %r75;
	shl.b32 	%r840, %r839, 2;
	add.s32 	%r841, %r828, %r840;
	add.s32 	%r547, %r841, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r673, %r674, %r675, %r676}, [%r547];
	// end inline asm
	add.s32 	%r842, %r81, %r75;
	shl.b32 	%r843, %r842, 2;
	add.s32 	%r844, %r828, %r843;
	add.s32 	%r552, %r844, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r721, %r722, %r723, %r724}, [%r552];
	// end inline asm
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	shl.b32 	%r845, %r1247, 12;
	add.s32 	%r846, %r1245, %r845;
	add.s32 	%r847, %r846, 16384;
	add.s32 	%r849, %r847, %r848;
	ld.shared.u32 	%r557, [%r849];
	add.s32 	%r850, %r83, %r84;
	shl.b32 	%r851, %r850, 2;
	add.s32 	%r852, %r847, %r851;
	ld.shared.u32 	%r558, [%r852+512];
	ld.shared.u32 	%r605, [%r852+1024];
	ld.shared.u32 	%r606, [%r852+1536];
	add.s32 	%r854, %r847, %r853;
	ld.shared.u32 	%r653, [%r854];
	ld.shared.u32 	%r654, [%r852+2560];
	ld.shared.u32 	%r701, [%r852+3072];
	ld.shared.u32 	%r702, [%r852+3584];
	add.s32 	%r856, %r847, %r855;
	shl.b32 	%r857, %r84, 2;
	add.s32 	%r858, %r856, %r857;
	ld.shared.u32 	%r563, [%r858];
	ld.shared.u32 	%r564, [%r858+512];
	ld.shared.u32 	%r611, [%r858+1024];
	ld.shared.u32 	%r612, [%r858+1536];
	shl.b32 	%r859, %r86, 2;
	add.s32 	%r860, %r856, %r859;
	ld.shared.u32 	%r659, [%r860];
	ld.shared.u32 	%r660, [%r858+2560];
	ld.shared.u32 	%r707, [%r858+3072];
	ld.shared.u32 	%r708, [%r858+3584];
	add.s32 	%r862, %r847, %r861;
	add.s32 	%r863, %r862, %r857;
	ld.shared.u32 	%r569, [%r863];
	ld.shared.u32 	%r570, [%r863+512];
	ld.shared.u32 	%r617, [%r863+1024];
	ld.shared.u32 	%r618, [%r863+1536];
	add.s32 	%r864, %r862, %r859;
	ld.shared.u32 	%r665, [%r864];
	ld.shared.u32 	%r666, [%r863+2560];
	ld.shared.u32 	%r713, [%r863+3072];
	ld.shared.u32 	%r714, [%r863+3584];
	add.s32 	%r866, %r847, %r865;
	add.s32 	%r867, %r866, %r857;
	ld.shared.u32 	%r575, [%r867];
	ld.shared.u32 	%r576, [%r867+512];
	ld.shared.u32 	%r623, [%r867+1024];
	ld.shared.u32 	%r624, [%r867+1536];
	add.s32 	%r868, %r866, %r859;
	ld.shared.u32 	%r671, [%r868];
	ld.shared.u32 	%r672, [%r867+2560];
	ld.shared.u32 	%r719, [%r867+3072];
	ld.shared.u32 	%r720, [%r867+3584];
	.loc	1 84 37                         // implicit_gemm_kernel.py:84:37
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f450, %f451, %f452, %f453 }, { %r553, %r554, %r555, %r556 }, { %r557, %r558 }, { %f450, %f451, %f452, %f453 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f454, %f455, %f456, %f457 }, { %r553, %r554, %r555, %r556 }, { %r563, %r564 }, { %f454, %f455, %f456, %f457 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f458, %f459, %f460, %f461 }, { %r553, %r554, %r555, %r556 }, { %r569, %r570 }, { %f458, %f459, %f460, %f461 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f462, %f463, %f464, %f465 }, { %r553, %r554, %r555, %r556 }, { %r575, %r576 }, { %f462, %f463, %f464, %f465 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f466, %f467, %f468, %f469 }, { %r577, %r578, %r579, %r580 }, { %r557, %r558 }, { %f466, %f467, %f468, %f469 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f470, %f471, %f472, %f473 }, { %r577, %r578, %r579, %r580 }, { %r563, %r564 }, { %f470, %f471, %f472, %f473 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f474, %f475, %f476, %f477 }, { %r577, %r578, %r579, %r580 }, { %r569, %r570 }, { %f474, %f475, %f476, %f477 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f478, %f479, %f480, %f481 }, { %r577, %r578, %r579, %r580 }, { %r575, %r576 }, { %f478, %f479, %f480, %f481 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f450, %f451, %f452, %f453 }, { %r601, %r602, %r603, %r604 }, { %r605, %r606 }, { %f450, %f451, %f452, %f453 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f454, %f455, %f456, %f457 }, { %r601, %r602, %r603, %r604 }, { %r611, %r612 }, { %f454, %f455, %f456, %f457 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f458, %f459, %f460, %f461 }, { %r601, %r602, %r603, %r604 }, { %r617, %r618 }, { %f458, %f459, %f460, %f461 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f462, %f463, %f464, %f465 }, { %r601, %r602, %r603, %r604 }, { %r623, %r624 }, { %f462, %f463, %f464, %f465 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f466, %f467, %f468, %f469 }, { %r625, %r626, %r627, %r628 }, { %r605, %r606 }, { %f466, %f467, %f468, %f469 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f470, %f471, %f472, %f473 }, { %r625, %r626, %r627, %r628 }, { %r611, %r612 }, { %f470, %f471, %f472, %f473 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f474, %f475, %f476, %f477 }, { %r625, %r626, %r627, %r628 }, { %r617, %r618 }, { %f474, %f475, %f476, %f477 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f478, %f479, %f480, %f481 }, { %r625, %r626, %r627, %r628 }, { %r623, %r624 }, { %f478, %f479, %f480, %f481 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f450, %f451, %f452, %f453 }, { %r649, %r650, %r651, %r652 }, { %r653, %r654 }, { %f450, %f451, %f452, %f453 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f454, %f455, %f456, %f457 }, { %r649, %r650, %r651, %r652 }, { %r659, %r660 }, { %f454, %f455, %f456, %f457 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f458, %f459, %f460, %f461 }, { %r649, %r650, %r651, %r652 }, { %r665, %r666 }, { %f458, %f459, %f460, %f461 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f462, %f463, %f464, %f465 }, { %r649, %r650, %r651, %r652 }, { %r671, %r672 }, { %f462, %f463, %f464, %f465 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f466, %f467, %f468, %f469 }, { %r673, %r674, %r675, %r676 }, { %r653, %r654 }, { %f466, %f467, %f468, %f469 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f470, %f471, %f472, %f473 }, { %r673, %r674, %r675, %r676 }, { %r659, %r660 }, { %f470, %f471, %f472, %f473 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f474, %f475, %f476, %f477 }, { %r673, %r674, %r675, %r676 }, { %r665, %r666 }, { %f474, %f475, %f476, %f477 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f478, %f479, %f480, %f481 }, { %r673, %r674, %r675, %r676 }, { %r671, %r672 }, { %f478, %f479, %f480, %f481 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f450, %f451, %f452, %f453 }, { %r697, %r698, %r699, %r700 }, { %r701, %r702 }, { %f450, %f451, %f452, %f453 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f454, %f455, %f456, %f457 }, { %r697, %r698, %r699, %r700 }, { %r707, %r708 }, { %f454, %f455, %f456, %f457 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f458, %f459, %f460, %f461 }, { %r697, %r698, %r699, %r700 }, { %r713, %r714 }, { %f458, %f459, %f460, %f461 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f462, %f463, %f464, %f465 }, { %r697, %r698, %r699, %r700 }, { %r719, %r720 }, { %f462, %f463, %f464, %f465 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f466, %f467, %f468, %f469 }, { %r721, %r722, %r723, %r724 }, { %r701, %r702 }, { %f466, %f467, %f468, %f469 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f470, %f471, %f472, %f473 }, { %r721, %r722, %r723, %r724 }, { %r707, %r708 }, { %f470, %f471, %f472, %f473 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f474, %f475, %f476, %f477 }, { %r721, %r722, %r723, %r724 }, { %r713, %r714 }, { %f474, %f475, %f476, %f477 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f478, %f479, %f480, %f481 }, { %r721, %r722, %r723, %r724 }, { %r719, %r720 }, { %f478, %f479, %f480, %f481 };
	// end inline asm
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	add.s64 	%rd381, %rd381, 1;
	.loc	1 69 89                         // implicit_gemm_kernel.py:69:89
	add.s64 	%rd217, %rd59, %rd380;
	add.s64 	%rd218, %rd58, %rd380;
	add.s64 	%rd219, %rd57, %rd380;
	add.s64 	%rd220, %rd56, %rd380;
	add.s64 	%rd221, %rd55, %rd380;
	add.s64 	%rd222, %rd54, %rd380;
	add.s64 	%rd223, %rd53, %rd380;
	add.s64 	%rd224, %rd52, %rd380;
	add.s64 	%rd225, %rd51, %rd380;
	add.s64 	%rd226, %rd50, %rd380;
	add.s64 	%rd227, %rd49, %rd380;
	add.s64 	%rd228, %rd48, %rd380;
	add.s64 	%rd229, %rd47, %rd380;
	add.s64 	%rd230, %rd46, %rd380;
	add.s64 	%rd231, %rd45, %rd380;
	add.s64 	%rd232, %rd44, %rd380;
	add.s64 	%rd233, %rd43, %rd380;
	add.s64 	%rd234, %rd42, %rd380;
	add.s64 	%rd235, %rd41, %rd380;
	add.s64 	%rd236, %rd40, %rd380;
	add.s64 	%rd237, %rd39, %rd380;
	add.s64 	%rd238, %rd38, %rd380;
	add.s64 	%rd239, %rd37, %rd380;
	add.s64 	%rd240, %rd36, %rd380;
	add.s64 	%rd241, %rd35, %rd380;
	add.s64 	%rd242, %rd34, %rd380;
	add.s64 	%rd243, %rd33, %rd380;
	add.s64 	%rd244, %rd32, %rd380;
	add.s64 	%rd245, %rd31, %rd380;
	add.s64 	%rd246, %rd30, %rd380;
	add.s64 	%rd247, %rd29, %rd380;
	.loc	1 69 36                         // implicit_gemm_kernel.py:69:36
	add.s64 	%rd248, %rd28, %rd380;
	cvt.u32.u64 	%r869, %rd217;
	mul.wide.s32 	%rd249, %r869, 4;
	add.s64 	%rd177, %rd89, %rd249;
	cvt.u32.u64 	%r870, %rd218;
	mul.wide.s32 	%rd250, %r870, 4;
	add.s64 	%rd178, %rd89, %rd250;
	cvt.u32.u64 	%r871, %rd219;
	mul.wide.s32 	%rd251, %r871, 4;
	add.s64 	%rd179, %rd89, %rd251;
	cvt.u32.u64 	%r872, %rd220;
	mul.wide.s32 	%rd252, %r872, 4;
	add.s64 	%rd180, %rd89, %rd252;
	cvt.u32.u64 	%r873, %rd221;
	mul.wide.s32 	%rd253, %r873, 4;
	add.s64 	%rd181, %rd89, %rd253;
	cvt.u32.u64 	%r874, %rd222;
	mul.wide.s32 	%rd254, %r874, 4;
	add.s64 	%rd182, %rd89, %rd254;
	cvt.u32.u64 	%r875, %rd223;
	mul.wide.s32 	%rd255, %r875, 4;
	add.s64 	%rd183, %rd89, %rd255;
	cvt.u32.u64 	%r876, %rd224;
	mul.wide.s32 	%rd256, %r876, 4;
	add.s64 	%rd184, %rd89, %rd256;
	cvt.u32.u64 	%r877, %rd225;
	mul.wide.s32 	%rd257, %r877, 4;
	add.s64 	%rd185, %rd89, %rd257;
	cvt.u32.u64 	%r878, %rd226;
	mul.wide.s32 	%rd258, %r878, 4;
	add.s64 	%rd186, %rd89, %rd258;
	cvt.u32.u64 	%r879, %rd227;
	mul.wide.s32 	%rd259, %r879, 4;
	add.s64 	%rd187, %rd89, %rd259;
	cvt.u32.u64 	%r880, %rd228;
	mul.wide.s32 	%rd260, %r880, 4;
	add.s64 	%rd188, %rd89, %rd260;
	cvt.u32.u64 	%r881, %rd229;
	mul.wide.s32 	%rd261, %r881, 4;
	add.s64 	%rd189, %rd89, %rd261;
	cvt.u32.u64 	%r882, %rd230;
	mul.wide.s32 	%rd262, %r882, 4;
	add.s64 	%rd190, %rd89, %rd262;
	cvt.u32.u64 	%r883, %rd231;
	mul.wide.s32 	%rd263, %r883, 4;
	add.s64 	%rd191, %rd89, %rd263;
	cvt.u32.u64 	%r884, %rd232;
	mul.wide.s32 	%rd264, %r884, 4;
	add.s64 	%rd192, %rd89, %rd264;
	cvt.u32.u64 	%r885, %rd233;
	mul.wide.s32 	%rd265, %r885, 4;
	add.s64 	%rd193, %rd89, %rd265;
	cvt.u32.u64 	%r886, %rd234;
	mul.wide.s32 	%rd266, %r886, 4;
	add.s64 	%rd194, %rd89, %rd266;
	cvt.u32.u64 	%r887, %rd235;
	mul.wide.s32 	%rd267, %r887, 4;
	add.s64 	%rd195, %rd89, %rd267;
	cvt.u32.u64 	%r888, %rd236;
	mul.wide.s32 	%rd268, %r888, 4;
	add.s64 	%rd196, %rd89, %rd268;
	cvt.u32.u64 	%r889, %rd237;
	mul.wide.s32 	%rd269, %r889, 4;
	add.s64 	%rd197, %rd89, %rd269;
	cvt.u32.u64 	%r890, %rd238;
	mul.wide.s32 	%rd270, %r890, 4;
	add.s64 	%rd198, %rd89, %rd270;
	cvt.u32.u64 	%r891, %rd239;
	mul.wide.s32 	%rd271, %r891, 4;
	add.s64 	%rd199, %rd89, %rd271;
	cvt.u32.u64 	%r892, %rd240;
	mul.wide.s32 	%rd272, %r892, 4;
	add.s64 	%rd200, %rd89, %rd272;
	cvt.u32.u64 	%r893, %rd241;
	mul.wide.s32 	%rd273, %r893, 4;
	add.s64 	%rd201, %rd89, %rd273;
	cvt.u32.u64 	%r894, %rd242;
	mul.wide.s32 	%rd274, %r894, 4;
	add.s64 	%rd202, %rd89, %rd274;
	cvt.u32.u64 	%r895, %rd243;
	mul.wide.s32 	%rd275, %r895, 4;
	add.s64 	%rd203, %rd89, %rd275;
	cvt.u32.u64 	%r896, %rd244;
	mul.wide.s32 	%rd276, %r896, 4;
	add.s64 	%rd204, %rd89, %rd276;
	cvt.u32.u64 	%r897, %rd245;
	mul.wide.s32 	%rd277, %r897, 4;
	add.s64 	%rd205, %rd89, %rd277;
	cvt.u32.u64 	%r898, %rd246;
	mul.wide.s32 	%rd278, %r898, 4;
	add.s64 	%rd206, %rd89, %rd278;
	cvt.u32.u64 	%r899, %rd247;
	mul.wide.s32 	%rd279, %r899, 4;
	add.s64 	%rd207, %rd89, %rd279;
	cvt.u32.u64 	%r900, %rd248;
	mul.wide.s32 	%rd280, %r900, 4;
	add.s64 	%rd208, %rd89, %rd280;
	.loc	1 70 98                         // implicit_gemm_kernel.py:70:98
	add.s64 	%rd281, %rd6, %rd380;
	setp.lt.s64 	%p101, %rd281, %rd4;
	.loc	1 73 54                         // implicit_gemm_kernel.py:73:54
	add.s64 	%rd282, %rd371, %rd380;
	.loc	1 75 22                         // implicit_gemm_kernel.py:75:22
	add.s64 	%rd283, %rd3, %rd372;
	add.s64 	%rd284, %rd3, %rd373;
	add.s64 	%rd285, %rd3, %rd374;
	add.s64 	%rd286, %rd3, %rd375;
	add.s64 	%rd287, %rd3, %rd376;
	add.s64 	%rd288, %rd3, %rd377;
	add.s64 	%rd289, %rd3, %rd378;
	.loc	1 73 20                         // implicit_gemm_kernel.py:73:20
	add.s64 	%rd290, %rd3, %rd379;
	cvt.u32.u64 	%r901, %rd283;
	mul.wide.s32 	%rd291, %r901, 4;
	add.s64 	%rd209, %rd90, %rd291;
	cvt.u32.u64 	%r902, %rd284;
	mul.wide.s32 	%rd292, %r902, 4;
	add.s64 	%rd210, %rd90, %rd292;
	cvt.u32.u64 	%r903, %rd285;
	mul.wide.s32 	%rd293, %r903, 4;
	add.s64 	%rd211, %rd90, %rd293;
	cvt.u32.u64 	%r904, %rd286;
	mul.wide.s32 	%rd294, %r904, 4;
	add.s64 	%rd212, %rd90, %rd294;
	cvt.u32.u64 	%r905, %rd287;
	mul.wide.s32 	%rd295, %r905, 4;
	add.s64 	%rd213, %rd90, %rd295;
	cvt.u32.u64 	%r906, %rd288;
	mul.wide.s32 	%rd296, %r906, 4;
	add.s64 	%rd214, %rd90, %rd296;
	cvt.u32.u64 	%r907, %rd289;
	mul.wide.s32 	%rd297, %r907, 4;
	add.s64 	%rd215, %rd90, %rd297;
	cvt.u32.u64 	%r908, %rd290;
	mul.wide.s32 	%rd298, %r908, 4;
	add.s64 	%rd216, %rd90, %rd298;
	cvt.u32.u64 	%r909, %rd282;
	add.s32 	%r910, %r909, 32;
	.loc	1 77 72                         // implicit_gemm_kernel.py:77:72
	setp.lt.s32 	%p102, %r910, %r29;
	add.s32 	%r911, %r909, 36;
	setp.lt.s32 	%p103, %r911, %r29;
	add.s32 	%r912, %r909, 40;
	setp.lt.s32 	%p104, %r912, %r29;
	add.s32 	%r913, %r909, 44;
	setp.lt.s32 	%p105, %r913, %r29;
	add.s32 	%r914, %r909, 48;
	setp.lt.s32 	%p106, %r914, %r29;
	add.s32 	%r915, %r909, 52;
	setp.lt.s32 	%p107, %r915, %r29;
	add.s32 	%r916, %r909, 56;
	setp.lt.s32 	%p108, %r916, %r29;
	add.s32 	%r917, %r909, 60;
	setp.lt.s32 	%p109, %r917, %r29;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	bar.sync 	0;
	selp.b32 	%r918, 4, 0, %p101;
	selp.b32 	%r919, %r918, 0, %p26;
	selp.b32 	%r746, %r919, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r349 + 0 ], [ %rd177 + 0 ], 0x4, %r746;
	// end inline asm
	selp.b32 	%r920, %r918, 0, %p27;
	selp.b32 	%r748, %r920, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r351 + 0 ], [ %rd178 + 0 ], 0x4, %r748;
	// end inline asm
	selp.b32 	%r921, %r918, 0, %p28;
	selp.b32 	%r750, %r921, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r353 + 0 ], [ %rd179 + 0 ], 0x4, %r750;
	// end inline asm
	selp.b32 	%r922, %r918, 0, %p29;
	selp.b32 	%r752, %r922, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r355 + 0 ], [ %rd180 + 0 ], 0x4, %r752;
	// end inline asm
	selp.b32 	%r923, %r918, 0, %p30;
	selp.b32 	%r754, %r923, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r357 + 0 ], [ %rd181 + 0 ], 0x4, %r754;
	// end inline asm
	selp.b32 	%r924, %r918, 0, %p31;
	selp.b32 	%r756, %r924, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r359 + 0 ], [ %rd182 + 0 ], 0x4, %r756;
	// end inline asm
	selp.b32 	%r925, %r918, 0, %p32;
	selp.b32 	%r758, %r925, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r361 + 0 ], [ %rd183 + 0 ], 0x4, %r758;
	// end inline asm
	selp.b32 	%r926, %r918, 0, %p33;
	selp.b32 	%r760, %r926, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r363 + 0 ], [ %rd184 + 0 ], 0x4, %r760;
	// end inline asm
	selp.b32 	%r927, %r918, 0, %p34;
	selp.b32 	%r762, %r927, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r365 + 0 ], [ %rd185 + 0 ], 0x4, %r762;
	// end inline asm
	selp.b32 	%r928, %r918, 0, %p35;
	selp.b32 	%r764, %r928, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r367 + 0 ], [ %rd186 + 0 ], 0x4, %r764;
	// end inline asm
	selp.b32 	%r929, %r918, 0, %p36;
	selp.b32 	%r766, %r929, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r369 + 0 ], [ %rd187 + 0 ], 0x4, %r766;
	// end inline asm
	selp.b32 	%r930, %r918, 0, %p37;
	selp.b32 	%r768, %r930, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r371 + 0 ], [ %rd188 + 0 ], 0x4, %r768;
	// end inline asm
	selp.b32 	%r931, %r918, 0, %p38;
	selp.b32 	%r770, %r931, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r373 + 0 ], [ %rd189 + 0 ], 0x4, %r770;
	// end inline asm
	selp.b32 	%r932, %r918, 0, %p39;
	selp.b32 	%r772, %r932, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r375 + 0 ], [ %rd190 + 0 ], 0x4, %r772;
	// end inline asm
	selp.b32 	%r933, %r918, 0, %p40;
	selp.b32 	%r774, %r933, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r377 + 0 ], [ %rd191 + 0 ], 0x4, %r774;
	// end inline asm
	selp.b32 	%r934, %r918, 0, %p41;
	selp.b32 	%r776, %r934, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r379 + 0 ], [ %rd192 + 0 ], 0x4, %r776;
	// end inline asm
	selp.b32 	%r935, %r918, 0, %p42;
	selp.b32 	%r778, %r935, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r381 + 0 ], [ %rd193 + 0 ], 0x4, %r778;
	// end inline asm
	selp.b32 	%r936, %r918, 0, %p43;
	selp.b32 	%r780, %r936, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r383 + 0 ], [ %rd194 + 0 ], 0x4, %r780;
	// end inline asm
	selp.b32 	%r937, %r918, 0, %p44;
	selp.b32 	%r782, %r937, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r385 + 0 ], [ %rd195 + 0 ], 0x4, %r782;
	// end inline asm
	selp.b32 	%r938, %r918, 0, %p45;
	selp.b32 	%r784, %r938, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r387 + 0 ], [ %rd196 + 0 ], 0x4, %r784;
	// end inline asm
	selp.b32 	%r939, %r918, 0, %p46;
	selp.b32 	%r786, %r939, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r389 + 0 ], [ %rd197 + 0 ], 0x4, %r786;
	// end inline asm
	selp.b32 	%r940, %r918, 0, %p47;
	selp.b32 	%r788, %r940, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r391 + 0 ], [ %rd198 + 0 ], 0x4, %r788;
	// end inline asm
	selp.b32 	%r941, %r918, 0, %p48;
	selp.b32 	%r790, %r941, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r393 + 0 ], [ %rd199 + 0 ], 0x4, %r790;
	// end inline asm
	selp.b32 	%r942, %r918, 0, %p49;
	selp.b32 	%r792, %r942, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r395 + 0 ], [ %rd200 + 0 ], 0x4, %r792;
	// end inline asm
	selp.b32 	%r943, %r918, 0, %p50;
	selp.b32 	%r794, %r943, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r397 + 0 ], [ %rd201 + 0 ], 0x4, %r794;
	// end inline asm
	selp.b32 	%r944, %r918, 0, %p51;
	selp.b32 	%r796, %r944, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r399 + 0 ], [ %rd202 + 0 ], 0x4, %r796;
	// end inline asm
	selp.b32 	%r945, %r918, 0, %p52;
	selp.b32 	%r798, %r945, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r401 + 0 ], [ %rd203 + 0 ], 0x4, %r798;
	// end inline asm
	selp.b32 	%r946, %r918, 0, %p53;
	selp.b32 	%r800, %r946, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r403 + 0 ], [ %rd204 + 0 ], 0x4, %r800;
	// end inline asm
	selp.b32 	%r947, %r918, 0, %p54;
	selp.b32 	%r802, %r947, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r405 + 0 ], [ %rd205 + 0 ], 0x4, %r802;
	// end inline asm
	selp.b32 	%r948, %r918, 0, %p55;
	selp.b32 	%r804, %r948, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r407 + 0 ], [ %rd206 + 0 ], 0x4, %r804;
	// end inline asm
	selp.b32 	%r949, %r918, 0, %p56;
	selp.b32 	%r806, %r949, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r409 + 0 ], [ %rd207 + 0 ], 0x4, %r806;
	// end inline asm
	selp.b32 	%r950, %r918, 0, %p57;
	selp.b32 	%r808, %r950, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r411 + 0 ], [ %rd208 + 0 ], 0x4, %r808;
	// end inline asm
	cp.async.commit_group;
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	selp.b32 	%r951, 4, 0, %p102;
	selp.b32 	%r952, %r951, 0, %p7;
	selp.b32 	%r810, %r952, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r413 + 0 ], [ %rd209 + 0 ], 0x4, %r810;
	// end inline asm
	selp.b32 	%r953, 4, 0, %p103;
	selp.b32 	%r954, %r953, 0, %p7;
	selp.b32 	%r812, %r954, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r415 + 0 ], [ %rd210 + 0 ], 0x4, %r812;
	// end inline asm
	selp.b32 	%r955, 4, 0, %p104;
	selp.b32 	%r956, %r955, 0, %p7;
	selp.b32 	%r814, %r956, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r417 + 0 ], [ %rd211 + 0 ], 0x4, %r814;
	// end inline asm
	selp.b32 	%r957, 4, 0, %p105;
	selp.b32 	%r958, %r957, 0, %p7;
	selp.b32 	%r816, %r958, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r419 + 0 ], [ %rd212 + 0 ], 0x4, %r816;
	// end inline asm
	selp.b32 	%r959, 4, 0, %p106;
	selp.b32 	%r960, %r959, 0, %p7;
	selp.b32 	%r818, %r960, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r421 + 0 ], [ %rd213 + 0 ], 0x4, %r818;
	// end inline asm
	selp.b32 	%r961, 4, 0, %p107;
	selp.b32 	%r962, %r961, 0, %p7;
	selp.b32 	%r820, %r962, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r423 + 0 ], [ %rd214 + 0 ], 0x4, %r820;
	// end inline asm
	selp.b32 	%r963, 4, 0, %p108;
	selp.b32 	%r964, %r963, 0, %p7;
	selp.b32 	%r822, %r964, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r425 + 0 ], [ %rd215 + 0 ], 0x4, %r822;
	// end inline asm
	selp.b32 	%r965, 4, 0, %p109;
	selp.b32 	%r966, %r965, 0, %p7;
	selp.b32 	%r824, %r966, 0, %p99;
	// begin inline asm
	cp.async.ca.shared.global [ %r427 + 0 ], [ %rd216 + 0 ], 0x4, %r824;
	// end inline asm
	cp.async.commit_group;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	add.s64 	%rd380, %rd380, 32;
	add.s64 	%rd379, %rd379, %rd11;
	add.s64 	%rd378, %rd378, %rd11;
	add.s64 	%rd377, %rd377, %rd11;
	add.s64 	%rd376, %rd376, %rd11;
	add.s64 	%rd375, %rd375, %rd11;
	add.s64 	%rd374, %rd374, %rd11;
	add.s64 	%rd373, %rd373, %rd11;
	add.s64 	%rd372, %rd372, %rd11;
	setp.ne.s64 	%p110, %rd5, %rd381;
	@%p110 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_7;
$L__BB0_1:                              // %.._crit_edge14_crit_edge
	.loc	1 88 19                         // implicit_gemm_kernel.py:88:19
	shl.b32 	%r250, %r2, 5;
	.loc	1 87 10                         // implicit_gemm_kernel.py:87:10
	or.b32  	%r1252, %r250, %r5;
	.loc	1 99 12                         // implicit_gemm_kernel.py:99:12
	shr.u32 	%r1251, %r4, 2;
	shr.u32 	%r1250, %r6, 2;
	shr.u32 	%r251, %r4, 1;
	and.b32  	%r1249, %r251, 48;
	.loc	1 86 31                         // implicit_gemm_kernel.py:86:31
	shr.u32 	%r1248, %r4, 5;
	mov.b32 	%r1253, 0;
	mov.u32 	%r1254, %r1253;
	mov.u32 	%r1255, %r1253;
	mov.u32 	%r1256, %r1253;
	mov.u32 	%r1257, %r1253;
	mov.u32 	%r1258, %r1253;
	mov.u32 	%r1259, %r1253;
	mov.u32 	%r1260, %r1253;
	mov.u32 	%r1261, %r1253;
	mov.u32 	%r1262, %r1253;
	mov.u32 	%r1263, %r1253;
	mov.u32 	%r1264, %r1253;
	mov.u32 	%r1265, %r1253;
	mov.u32 	%r1266, %r1253;
	mov.u32 	%r1267, %r1253;
	mov.u32 	%r1268, %r1253;
	mov.u32 	%r1269, %r1253;
	mov.u32 	%r1270, %r1253;
	mov.u32 	%r1271, %r1253;
	mov.u32 	%r1272, %r1253;
	mov.u32 	%r1273, %r1253;
	mov.u32 	%r1274, %r1253;
	mov.u32 	%r1275, %r1253;
	mov.u32 	%r1276, %r1253;
	mov.u32 	%r1277, %r1253;
	mov.u32 	%r1278, %r1253;
	mov.u32 	%r1279, %r1253;
	mov.u32 	%r1280, %r1253;
	mov.u32 	%r1281, %r1253;
	mov.u32 	%r1282, %r1253;
	mov.u32 	%r1283, %r1253;
	mov.u32 	%r1284, %r1253;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	bra.uni 	$L__BB0_10;
$L__BB0_9:                              // %._crit_edge14.loopexit
	.loc	1 99 12                         // implicit_gemm_kernel.py:99:12
	mov.b32 	%r1253, %f450;
	mov.b32 	%r1254, %f451;
	mov.b32 	%r1255, %f452;
	mov.b32 	%r1256, %f453;
	mov.b32 	%r1257, %f454;
	mov.b32 	%r1258, %f455;
	mov.b32 	%r1259, %f456;
	mov.b32 	%r1260, %f457;
	mov.b32 	%r1261, %f458;
	mov.b32 	%r1262, %f459;
	mov.b32 	%r1263, %f460;
	mov.b32 	%r1264, %f461;
	mov.b32 	%r1265, %f462;
	mov.b32 	%r1266, %f463;
	mov.b32 	%r1267, %f464;
	mov.b32 	%r1268, %f465;
	mov.b32 	%r1269, %f466;
	mov.b32 	%r1270, %f467;
	mov.b32 	%r1271, %f468;
	mov.b32 	%r1272, %f469;
	mov.b32 	%r1273, %f470;
	mov.b32 	%r1274, %f471;
	mov.b32 	%r1275, %f472;
	mov.b32 	%r1276, %f473;
	mov.b32 	%r1277, %f474;
	mov.b32 	%r1278, %f475;
	mov.b32 	%r1279, %f476;
	mov.b32 	%r1280, %f477;
	mov.b32 	%r1281, %f478;
	mov.b32 	%r1282, %f479;
	mov.b32 	%r1283, %f480;
	mov.b32 	%r1284, %f481;
$L__BB0_10:                             // %._crit_edge14
	.loc	1 86 31                         // implicit_gemm_kernel.py:86:31
	and.b32  	%r1095, %r1248, 3;
	.loc	1 86 42                         // implicit_gemm_kernel.py:86:42
	or.b32  	%r1096, %r1095, %r8;
	or.b32  	%r1097, %r1096, 4;
	or.b32  	%r1098, %r1096, 8;
	or.b32  	%r1099, %r1096, 12;
	or.b32  	%r1100, %r1096, 16;
	or.b32  	%r1101, %r1096, 20;
	or.b32  	%r1102, %r1096, 24;
	or.b32  	%r1103, %r1096, 28;
	or.b32  	%r1104, %r1096, 32;
	or.b32  	%r1105, %r1096, 36;
	or.b32  	%r1106, %r1096, 40;
	or.b32  	%r1107, %r1096, 44;
	or.b32  	%r1108, %r1096, 48;
	or.b32  	%r1109, %r1096, 52;
	or.b32  	%r1110, %r1096, 56;
	or.b32  	%r1111, %r1096, 60;
	or.b32  	%r1112, %r1096, 64;
	or.b32  	%r1113, %r1096, 68;
	or.b32  	%r1114, %r1096, 72;
	or.b32  	%r1115, %r1096, 76;
	or.b32  	%r1116, %r1096, 80;
	or.b32  	%r1117, %r1096, 84;
	or.b32  	%r1118, %r1096, 88;
	or.b32  	%r1119, %r1096, 92;
	or.b32  	%r1120, %r1096, 96;
	or.b32  	%r1121, %r1096, 100;
	or.b32  	%r1122, %r1096, 104;
	or.b32  	%r1123, %r1096, 108;
	or.b32  	%r1124, %r1096, 112;
	or.b32  	%r1125, %r1096, 116;
	or.b32  	%r1126, %r1096, 120;
	or.b32  	%r1127, %r1096, 124;
	.loc	1 86 61                         // implicit_gemm_kernel.py:86:61
	mul.lo.s32 	%r1128, %r1096, %r232;
	shl.b32 	%r1129, %r232, 2;
	add.s32 	%r1130, %r1128, %r1129;
	add.s32 	%r1131, %r1130, %r1129;
	add.s32 	%r1132, %r1131, %r1129;
	add.s32 	%r1133, %r1132, %r1129;
	add.s32 	%r1134, %r1133, %r1129;
	add.s32 	%r1135, %r1134, %r1129;
	add.s32 	%r1136, %r1135, %r1129;
	add.s32 	%r1137, %r1136, %r1129;
	add.s32 	%r1138, %r1137, %r1129;
	add.s32 	%r1139, %r1138, %r1129;
	add.s32 	%r1140, %r1139, %r1129;
	add.s32 	%r1141, %r1140, %r1129;
	add.s32 	%r1142, %r1141, %r1129;
	add.s32 	%r1143, %r1142, %r1129;
	add.s32 	%r1144, %r1143, %r1129;
	add.s32 	%r1145, %r1144, %r1129;
	add.s32 	%r1146, %r1145, %r1129;
	add.s32 	%r1147, %r1146, %r1129;
	add.s32 	%r1148, %r1147, %r1129;
	add.s32 	%r1149, %r1148, %r1129;
	add.s32 	%r1150, %r1149, %r1129;
	add.s32 	%r1151, %r1150, %r1129;
	add.s32 	%r1152, %r1151, %r1129;
	add.s32 	%r1153, %r1152, %r1129;
	add.s32 	%r1154, %r1153, %r1129;
	add.s32 	%r1155, %r1154, %r1129;
	add.s32 	%r1156, %r1155, %r1129;
	add.s32 	%r1157, %r1156, %r1129;
	add.s32 	%r1158, %r1157, %r1129;
	add.s32 	%r1159, %r1158, %r1129;
	add.s32 	%r1160, %r1159, %r1129;
	.loc	1 88 10                         // implicit_gemm_kernel.py:88:10
	add.s32 	%r1161, %r1252, %r1128;
	add.s32 	%r1162, %r1252, %r1130;
	add.s32 	%r1163, %r1252, %r1131;
	add.s32 	%r1164, %r1252, %r1132;
	add.s32 	%r1165, %r1252, %r1133;
	add.s32 	%r1166, %r1252, %r1134;
	add.s32 	%r1167, %r1252, %r1135;
	add.s32 	%r1168, %r1252, %r1136;
	add.s32 	%r1169, %r1252, %r1137;
	add.s32 	%r1170, %r1252, %r1138;
	add.s32 	%r1171, %r1252, %r1139;
	add.s32 	%r1172, %r1252, %r1140;
	add.s32 	%r1173, %r1252, %r1141;
	add.s32 	%r1174, %r1252, %r1142;
	add.s32 	%r1175, %r1252, %r1143;
	add.s32 	%r1176, %r1252, %r1144;
	add.s32 	%r1177, %r1252, %r1145;
	add.s32 	%r1178, %r1252, %r1146;
	add.s32 	%r1179, %r1252, %r1147;
	add.s32 	%r1180, %r1252, %r1148;
	add.s32 	%r1181, %r1252, %r1149;
	add.s32 	%r1182, %r1252, %r1150;
	add.s32 	%r1183, %r1252, %r1151;
	add.s32 	%r1184, %r1252, %r1152;
	add.s32 	%r1185, %r1252, %r1153;
	add.s32 	%r1186, %r1252, %r1154;
	add.s32 	%r1187, %r1252, %r1155;
	add.s32 	%r1188, %r1252, %r1156;
	add.s32 	%r1189, %r1252, %r1157;
	add.s32 	%r1190, %r1252, %r1158;
	add.s32 	%r1191, %r1252, %r1159;
	add.s32 	%r1192, %r1252, %r1160;
	.loc	1 86 8                          // implicit_gemm_kernel.py:86:8
	mul.wide.s32 	%rd331, %r1161, 4;
	add.s64 	%rd299, %rd91, %rd331;
	mul.wide.s32 	%rd332, %r1162, 4;
	add.s64 	%rd300, %rd91, %rd332;
	mul.wide.s32 	%rd333, %r1163, 4;
	add.s64 	%rd301, %rd91, %rd333;
	mul.wide.s32 	%rd334, %r1164, 4;
	add.s64 	%rd302, %rd91, %rd334;
	mul.wide.s32 	%rd335, %r1165, 4;
	add.s64 	%rd303, %rd91, %rd335;
	mul.wide.s32 	%rd336, %r1166, 4;
	add.s64 	%rd304, %rd91, %rd336;
	mul.wide.s32 	%rd337, %r1167, 4;
	add.s64 	%rd305, %rd91, %rd337;
	mul.wide.s32 	%rd338, %r1168, 4;
	add.s64 	%rd306, %rd91, %rd338;
	mul.wide.s32 	%rd339, %r1169, 4;
	add.s64 	%rd307, %rd91, %rd339;
	mul.wide.s32 	%rd340, %r1170, 4;
	add.s64 	%rd308, %rd91, %rd340;
	mul.wide.s32 	%rd341, %r1171, 4;
	add.s64 	%rd309, %rd91, %rd341;
	mul.wide.s32 	%rd342, %r1172, 4;
	add.s64 	%rd310, %rd91, %rd342;
	mul.wide.s32 	%rd343, %r1173, 4;
	add.s64 	%rd311, %rd91, %rd343;
	mul.wide.s32 	%rd344, %r1174, 4;
	add.s64 	%rd312, %rd91, %rd344;
	mul.wide.s32 	%rd345, %r1175, 4;
	add.s64 	%rd313, %rd91, %rd345;
	mul.wide.s32 	%rd346, %r1176, 4;
	add.s64 	%rd314, %rd91, %rd346;
	mul.wide.s32 	%rd347, %r1177, 4;
	add.s64 	%rd315, %rd91, %rd347;
	mul.wide.s32 	%rd348, %r1178, 4;
	add.s64 	%rd316, %rd91, %rd348;
	mul.wide.s32 	%rd349, %r1179, 4;
	add.s64 	%rd317, %rd91, %rd349;
	mul.wide.s32 	%rd350, %r1180, 4;
	add.s64 	%rd318, %rd91, %rd350;
	mul.wide.s32 	%rd351, %r1181, 4;
	add.s64 	%rd319, %rd91, %rd351;
	mul.wide.s32 	%rd352, %r1182, 4;
	add.s64 	%rd320, %rd91, %rd352;
	mul.wide.s32 	%rd353, %r1183, 4;
	add.s64 	%rd321, %rd91, %rd353;
	mul.wide.s32 	%rd354, %r1184, 4;
	add.s64 	%rd322, %rd91, %rd354;
	mul.wide.s32 	%rd355, %r1185, 4;
	add.s64 	%rd323, %rd91, %rd355;
	mul.wide.s32 	%rd356, %r1186, 4;
	add.s64 	%rd324, %rd91, %rd356;
	mul.wide.s32 	%rd357, %r1187, 4;
	add.s64 	%rd325, %rd91, %rd357;
	mul.wide.s32 	%rd358, %r1188, 4;
	add.s64 	%rd326, %rd91, %rd358;
	mul.wide.s32 	%rd359, %r1189, 4;
	add.s64 	%rd327, %rd91, %rd359;
	mul.wide.s32 	%rd360, %r1190, 4;
	add.s64 	%rd328, %rd91, %rd360;
	mul.wide.s32 	%rd361, %r1191, 4;
	add.s64 	%rd329, %rd91, %rd361;
	mul.wide.s32 	%rd362, %r1192, 4;
	add.s64 	%rd330, %rd91, %rd362;
	.loc	1 90 67                         // implicit_gemm_kernel.py:90:67
	setp.lt.s32 	%p176, %r1096, %r230;
	setp.lt.s32 	%p177, %r1097, %r230;
	setp.lt.s32 	%p178, %r1098, %r230;
	setp.lt.s32 	%p179, %r1099, %r230;
	setp.lt.s32 	%p180, %r1100, %r230;
	setp.lt.s32 	%p181, %r1101, %r230;
	setp.lt.s32 	%p182, %r1102, %r230;
	setp.lt.s32 	%p183, %r1103, %r230;
	setp.lt.s32 	%p184, %r1104, %r230;
	setp.lt.s32 	%p185, %r1105, %r230;
	setp.lt.s32 	%p186, %r1106, %r230;
	setp.lt.s32 	%p187, %r1107, %r230;
	setp.lt.s32 	%p188, %r1108, %r230;
	setp.lt.s32 	%p189, %r1109, %r230;
	setp.lt.s32 	%p190, %r1110, %r230;
	setp.lt.s32 	%p191, %r1111, %r230;
	setp.lt.s32 	%p192, %r1112, %r230;
	setp.lt.s32 	%p193, %r1113, %r230;
	setp.lt.s32 	%p194, %r1114, %r230;
	setp.lt.s32 	%p195, %r1115, %r230;
	setp.lt.s32 	%p196, %r1116, %r230;
	setp.lt.s32 	%p197, %r1117, %r230;
	setp.lt.s32 	%p198, %r1118, %r230;
	setp.lt.s32 	%p199, %r1119, %r230;
	setp.lt.s32 	%p200, %r1120, %r230;
	setp.lt.s32 	%p201, %r1121, %r230;
	setp.lt.s32 	%p202, %r1122, %r230;
	setp.lt.s32 	%p203, %r1123, %r230;
	setp.lt.s32 	%p204, %r1124, %r230;
	setp.lt.s32 	%p205, %r1125, %r230;
	setp.lt.s32 	%p206, %r1126, %r230;
	setp.lt.s32 	%p207, %r1127, %r230;
	.loc	1 91 62                         // implicit_gemm_kernel.py:91:62
	setp.lt.s32 	%p208, %r1252, %r232;
	.loc	1 91 8                          // implicit_gemm_kernel.py:91:8
	and.pred  	%p144, %p176, %p208;
	and.pred  	%p145, %p177, %p208;
	and.pred  	%p146, %p178, %p208;
	and.pred  	%p147, %p179, %p208;
	and.pred  	%p148, %p180, %p208;
	and.pred  	%p149, %p181, %p208;
	and.pred  	%p150, %p182, %p208;
	and.pred  	%p151, %p183, %p208;
	and.pred  	%p152, %p184, %p208;
	and.pred  	%p153, %p185, %p208;
	and.pred  	%p154, %p186, %p208;
	and.pred  	%p155, %p187, %p208;
	and.pred  	%p156, %p188, %p208;
	and.pred  	%p157, %p189, %p208;
	and.pred  	%p158, %p190, %p208;
	and.pred  	%p159, %p191, %p208;
	and.pred  	%p160, %p192, %p208;
	and.pred  	%p161, %p193, %p208;
	and.pred  	%p162, %p194, %p208;
	and.pred  	%p163, %p195, %p208;
	and.pred  	%p164, %p196, %p208;
	and.pred  	%p165, %p197, %p208;
	and.pred  	%p166, %p198, %p208;
	and.pred  	%p167, %p199, %p208;
	and.pred  	%p168, %p200, %p208;
	and.pred  	%p169, %p201, %p208;
	and.pred  	%p170, %p202, %p208;
	and.pred  	%p171, %p203, %p208;
	and.pred  	%p172, %p204, %p208;
	and.pred  	%p173, %p205, %p208;
	and.pred  	%p174, %p206, %p208;
	and.pred  	%p175, %p207, %p208;
	.loc	1 99 12                         // implicit_gemm_kernel.py:99:12
	bar.sync 	0;
	shl.b32 	%r1193, %r4, 7;
	and.b32  	%r1194, %r1193, 384;
	and.b32  	%r1195, %r1251, 3;
	or.b32  	%r1196, %r1250, %r1249;
	or.b32  	%r1197, %r1196, %r1195;
	or.b32  	%r1198, %r1197, %r1194;
	shl.b32 	%r1199, %r4, 6;
	and.b32  	%r1200, %r1199, 1984;
	or.b32  	%r1201, %r1095, %r1200;
	shr.u32 	%r1202, %r1194, 4;
	add.s32 	%r1204, %r1245, %r1202;
	shl.b32 	%r1205, %r1198, 2;
	add.s32 	%r967, %r1204, %r1205;
	mov.pred 	%p112, -1;
	// begin inline asm
	@%p112 st.shared.b32 [ %r967 + 0 ], %r1253;
	// end inline asm
	or.b32  	%r1206, %r1198, 64;
	shr.u32 	%r1207, %r1206, 4;
	and.b32  	%r1208, %r1207, 28;
	add.s32 	%r1209, %r1245, %r1208;
	add.s32 	%r1210, %r1209, %r1205;
	add.s32 	%r969, %r1210, 256;
	// begin inline asm
	@%p112 st.shared.b32 [ %r969 + 0 ], %r1254;
	// end inline asm
	add.s32 	%r971, %r967, 32;
	// begin inline asm
	@%p112 st.shared.b32 [ %r971 + 0 ], %r1255;
	// end inline asm
	add.s32 	%r973, %r1210, 288;
	// begin inline asm
	@%p112 st.shared.b32 [ %r973 + 0 ], %r1256;
	// end inline asm
	or.b32  	%r1211, %r1198, 512;
	shr.u32 	%r1212, %r1211, 4;
	and.b32  	%r1213, %r1212, 56;
	add.s32 	%r1214, %r1245, %r1213;
	add.s32 	%r1215, %r1214, %r1205;
	add.s32 	%r975, %r1215, 2048;
	// begin inline asm
	@%p112 st.shared.b32 [ %r975 + 0 ], %r1257;
	// end inline asm
	or.b32  	%r1216, %r1198, 576;
	shr.u32 	%r1217, %r1216, 4;
	and.b32  	%r1218, %r1217, 60;
	add.s32 	%r1219, %r1245, %r1218;
	add.s32 	%r1220, %r1219, %r1205;
	add.s32 	%r977, %r1220, 2304;
	// begin inline asm
	@%p112 st.shared.b32 [ %r977 + 0 ], %r1258;
	// end inline asm
	add.s32 	%r979, %r1215, 2080;
	// begin inline asm
	@%p112 st.shared.b32 [ %r979 + 0 ], %r1259;
	// end inline asm
	add.s32 	%r981, %r1220, 2336;
	// begin inline asm
	@%p112 st.shared.b32 [ %r981 + 0 ], %r1260;
	// end inline asm
	or.b32  	%r1221, %r1198, 1024;
	shr.u32 	%r1222, %r1221, 4;
	and.b32  	%r1223, %r1222, 88;
	add.s32 	%r1224, %r1245, %r1223;
	add.s32 	%r1225, %r1224, %r1205;
	add.s32 	%r983, %r1225, 4096;
	// begin inline asm
	@%p112 st.shared.b32 [ %r983 + 0 ], %r1261;
	// end inline asm
	or.b32  	%r1226, %r1198, 1088;
	shr.u32 	%r1227, %r1226, 4;
	and.b32  	%r1228, %r1227, 92;
	add.s32 	%r1229, %r1245, %r1228;
	add.s32 	%r1230, %r1229, %r1205;
	add.s32 	%r985, %r1230, 4352;
	// begin inline asm
	@%p112 st.shared.b32 [ %r985 + 0 ], %r1262;
	// end inline asm
	add.s32 	%r987, %r1225, 4128;
	// begin inline asm
	@%p112 st.shared.b32 [ %r987 + 0 ], %r1263;
	// end inline asm
	add.s32 	%r989, %r1230, 4384;
	// begin inline asm
	@%p112 st.shared.b32 [ %r989 + 0 ], %r1264;
	// end inline asm
	or.b32  	%r1231, %r1198, 1536;
	shr.u32 	%r1232, %r1231, 4;
	and.b32  	%r1233, %r1232, 120;
	add.s32 	%r1234, %r1245, %r1233;
	add.s32 	%r1235, %r1234, %r1205;
	add.s32 	%r991, %r1235, 6144;
	// begin inline asm
	@%p112 st.shared.b32 [ %r991 + 0 ], %r1265;
	// end inline asm
	or.b32  	%r1236, %r1198, 1600;
	shr.u32 	%r1237, %r1236, 4;
	and.b32  	%r1238, %r1237, 124;
	add.s32 	%r1239, %r1245, %r1238;
	add.s32 	%r1240, %r1239, %r1205;
	add.s32 	%r993, %r1240, 6400;
	// begin inline asm
	@%p112 st.shared.b32 [ %r993 + 0 ], %r1266;
	// end inline asm
	add.s32 	%r995, %r1235, 6176;
	// begin inline asm
	@%p112 st.shared.b32 [ %r995 + 0 ], %r1267;
	// end inline asm
	add.s32 	%r997, %r1240, 6432;
	// begin inline asm
	@%p112 st.shared.b32 [ %r997 + 0 ], %r1268;
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r1241, %r1200, 4;
	add.s32 	%r1242, %r1245, %r1241;
	shl.b32 	%r1243, %r1201, 2;
	add.s32 	%r1244, %r1242, %r1243;
	ld.shared.u32 	%r1032, [%r1244];
	ld.shared.u32 	%r1034, [%r1244+16];
	ld.shared.u32 	%r1036, [%r1244+32];
	ld.shared.u32 	%r1038, [%r1244+48];
	ld.shared.u32 	%r1040, [%r1244+64];
	ld.shared.u32 	%r1042, [%r1244+80];
	ld.shared.u32 	%r1044, [%r1244+96];
	ld.shared.u32 	%r1046, [%r1244+112];
	ld.shared.u32 	%r1048, [%r1244+128];
	ld.shared.u32 	%r1050, [%r1244+144];
	ld.shared.u32 	%r1052, [%r1244+160];
	ld.shared.u32 	%r1054, [%r1244+176];
	ld.shared.u32 	%r1056, [%r1244+192];
	ld.shared.u32 	%r1058, [%r1244+208];
	ld.shared.u32 	%r1060, [%r1244+224];
	ld.shared.u32 	%r1062, [%r1244+240];
	bar.sync 	0;
	// begin inline asm
	@%p112 st.shared.b32 [ %r967 + 0 ], %r1269;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r969 + 0 ], %r1270;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r971 + 0 ], %r1271;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r973 + 0 ], %r1272;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r975 + 0 ], %r1273;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r977 + 0 ], %r1274;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r979 + 0 ], %r1275;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r981 + 0 ], %r1276;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r983 + 0 ], %r1277;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r985 + 0 ], %r1278;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r987 + 0 ], %r1279;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r989 + 0 ], %r1280;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r991 + 0 ], %r1281;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r993 + 0 ], %r1282;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r995 + 0 ], %r1283;
	// end inline asm
	// begin inline asm
	@%p112 st.shared.b32 [ %r997 + 0 ], %r1284;
	// end inline asm
	bar.sync 	0;
	ld.shared.u32 	%r1064, [%r1244];
	ld.shared.u32 	%r1066, [%r1244+16];
	ld.shared.u32 	%r1068, [%r1244+32];
	ld.shared.u32 	%r1070, [%r1244+48];
	ld.shared.u32 	%r1072, [%r1244+64];
	ld.shared.u32 	%r1074, [%r1244+80];
	ld.shared.u32 	%r1076, [%r1244+96];
	ld.shared.u32 	%r1078, [%r1244+112];
	ld.shared.u32 	%r1080, [%r1244+128];
	ld.shared.u32 	%r1082, [%r1244+144];
	ld.shared.u32 	%r1084, [%r1244+160];
	ld.shared.u32 	%r1086, [%r1244+176];
	ld.shared.u32 	%r1088, [%r1244+192];
	ld.shared.u32 	%r1090, [%r1244+208];
	ld.shared.u32 	%r1092, [%r1244+224];
	ld.shared.u32 	%r1094, [%r1244+240];
	// begin inline asm
	mov.u32 %r1031, 0x0;
	@%p144 atom.global.gpu.acq_rel.add.f32 %r1031, [ %rd299 + 0 ], %r1032;
	// end inline asm
	// begin inline asm
	mov.u32 %r1033, 0x0;
	@%p145 atom.global.gpu.acq_rel.add.f32 %r1033, [ %rd300 + 0 ], %r1034;
	// end inline asm
	// begin inline asm
	mov.u32 %r1035, 0x0;
	@%p146 atom.global.gpu.acq_rel.add.f32 %r1035, [ %rd301 + 0 ], %r1036;
	// end inline asm
	// begin inline asm
	mov.u32 %r1037, 0x0;
	@%p147 atom.global.gpu.acq_rel.add.f32 %r1037, [ %rd302 + 0 ], %r1038;
	// end inline asm
	// begin inline asm
	mov.u32 %r1039, 0x0;
	@%p148 atom.global.gpu.acq_rel.add.f32 %r1039, [ %rd303 + 0 ], %r1040;
	// end inline asm
	// begin inline asm
	mov.u32 %r1041, 0x0;
	@%p149 atom.global.gpu.acq_rel.add.f32 %r1041, [ %rd304 + 0 ], %r1042;
	// end inline asm
	// begin inline asm
	mov.u32 %r1043, 0x0;
	@%p150 atom.global.gpu.acq_rel.add.f32 %r1043, [ %rd305 + 0 ], %r1044;
	// end inline asm
	// begin inline asm
	mov.u32 %r1045, 0x0;
	@%p151 atom.global.gpu.acq_rel.add.f32 %r1045, [ %rd306 + 0 ], %r1046;
	// end inline asm
	// begin inline asm
	mov.u32 %r1047, 0x0;
	@%p152 atom.global.gpu.acq_rel.add.f32 %r1047, [ %rd307 + 0 ], %r1048;
	// end inline asm
	// begin inline asm
	mov.u32 %r1049, 0x0;
	@%p153 atom.global.gpu.acq_rel.add.f32 %r1049, [ %rd308 + 0 ], %r1050;
	// end inline asm
	// begin inline asm
	mov.u32 %r1051, 0x0;
	@%p154 atom.global.gpu.acq_rel.add.f32 %r1051, [ %rd309 + 0 ], %r1052;
	// end inline asm
	// begin inline asm
	mov.u32 %r1053, 0x0;
	@%p155 atom.global.gpu.acq_rel.add.f32 %r1053, [ %rd310 + 0 ], %r1054;
	// end inline asm
	// begin inline asm
	mov.u32 %r1055, 0x0;
	@%p156 atom.global.gpu.acq_rel.add.f32 %r1055, [ %rd311 + 0 ], %r1056;
	// end inline asm
	// begin inline asm
	mov.u32 %r1057, 0x0;
	@%p157 atom.global.gpu.acq_rel.add.f32 %r1057, [ %rd312 + 0 ], %r1058;
	// end inline asm
	// begin inline asm
	mov.u32 %r1059, 0x0;
	@%p158 atom.global.gpu.acq_rel.add.f32 %r1059, [ %rd313 + 0 ], %r1060;
	// end inline asm
	// begin inline asm
	mov.u32 %r1061, 0x0;
	@%p159 atom.global.gpu.acq_rel.add.f32 %r1061, [ %rd314 + 0 ], %r1062;
	// end inline asm
	// begin inline asm
	mov.u32 %r1063, 0x0;
	@%p160 atom.global.gpu.acq_rel.add.f32 %r1063, [ %rd315 + 0 ], %r1064;
	// end inline asm
	// begin inline asm
	mov.u32 %r1065, 0x0;
	@%p161 atom.global.gpu.acq_rel.add.f32 %r1065, [ %rd316 + 0 ], %r1066;
	// end inline asm
	// begin inline asm
	mov.u32 %r1067, 0x0;
	@%p162 atom.global.gpu.acq_rel.add.f32 %r1067, [ %rd317 + 0 ], %r1068;
	// end inline asm
	// begin inline asm
	mov.u32 %r1069, 0x0;
	@%p163 atom.global.gpu.acq_rel.add.f32 %r1069, [ %rd318 + 0 ], %r1070;
	// end inline asm
	// begin inline asm
	mov.u32 %r1071, 0x0;
	@%p164 atom.global.gpu.acq_rel.add.f32 %r1071, [ %rd319 + 0 ], %r1072;
	// end inline asm
	// begin inline asm
	mov.u32 %r1073, 0x0;
	@%p165 atom.global.gpu.acq_rel.add.f32 %r1073, [ %rd320 + 0 ], %r1074;
	// end inline asm
	// begin inline asm
	mov.u32 %r1075, 0x0;
	@%p166 atom.global.gpu.acq_rel.add.f32 %r1075, [ %rd321 + 0 ], %r1076;
	// end inline asm
	// begin inline asm
	mov.u32 %r1077, 0x0;
	@%p167 atom.global.gpu.acq_rel.add.f32 %r1077, [ %rd322 + 0 ], %r1078;
	// end inline asm
	// begin inline asm
	mov.u32 %r1079, 0x0;
	@%p168 atom.global.gpu.acq_rel.add.f32 %r1079, [ %rd323 + 0 ], %r1080;
	// end inline asm
	// begin inline asm
	mov.u32 %r1081, 0x0;
	@%p169 atom.global.gpu.acq_rel.add.f32 %r1081, [ %rd324 + 0 ], %r1082;
	// end inline asm
	// begin inline asm
	mov.u32 %r1083, 0x0;
	@%p170 atom.global.gpu.acq_rel.add.f32 %r1083, [ %rd325 + 0 ], %r1084;
	// end inline asm
	// begin inline asm
	mov.u32 %r1085, 0x0;
	@%p171 atom.global.gpu.acq_rel.add.f32 %r1085, [ %rd326 + 0 ], %r1086;
	// end inline asm
	// begin inline asm
	mov.u32 %r1087, 0x0;
	@%p172 atom.global.gpu.acq_rel.add.f32 %r1087, [ %rd327 + 0 ], %r1088;
	// end inline asm
	// begin inline asm
	mov.u32 %r1089, 0x0;
	@%p173 atom.global.gpu.acq_rel.add.f32 %r1089, [ %rd328 + 0 ], %r1090;
	// end inline asm
	// begin inline asm
	mov.u32 %r1091, 0x0;
	@%p174 atom.global.gpu.acq_rel.add.f32 %r1091, [ %rd329 + 0 ], %r1092;
	// end inline asm
	// begin inline asm
	mov.u32 %r1093, 0x0;
	@%p175 atom.global.gpu.acq_rel.add.f32 %r1093, [ %rd330 + 0 ], %r1094;
	// end inline asm
	.loc	1 93 4                          // implicit_gemm_kernel.py:93:4
	ret;
$L__tmp7:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/allan/Programs/sparse-conv/implicit_gemm_kernel.py"
	.file	2 "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 174                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0xa7 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 105                                 // DW_AT_name
.b8 109
.b8 112
.b8 108
.b8 105
.b8 99
.b8 105
.b8 116
.b8 95
.b8 103
.b8 101
.b8 109
.b8 109
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 97
.b8 108
.b8 108
.b8 97
.b8 110
.b8 47
.b8 80
.b8 114
.b8 111
.b8 103
.b8 114
.b8 97
.b8 109
.b8 115
.b8 47
.b8 115
.b8 112
.b8 97
.b8 114
.b8 115
.b8 101
.b8 45
.b8 99
.b8 111
.b8 110
.b8 118
.b8 0
.b8 2                                   // Abbrev [2] 0x52:0x19 DW_TAG_subprogram
.b8 105                                 // DW_AT_name
.b8 109
.b8 112
.b8 108
.b8 105
.b8 99
.b8 105
.b8 116
.b8 95
.b8 99
.b8 111
.b8 110
.b8 118
.b8 51
.b8 100
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x6b:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 82                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x80:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 51                                  // DW_AT_call_line
.b8 30                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x98:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp6                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 65                                  // DW_AT_call_line
.b8 50                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
