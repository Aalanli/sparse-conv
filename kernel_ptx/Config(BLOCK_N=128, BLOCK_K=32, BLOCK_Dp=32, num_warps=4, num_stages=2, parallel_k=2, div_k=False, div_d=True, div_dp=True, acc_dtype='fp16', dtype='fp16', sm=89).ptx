//
// Generated by LLVM NVPTX Back-End
//

.version 8.2
.target sm_89
.address_size 64

	// .globl	implicit_conv3d_kernel  // -- Begin function implicit_conv3d_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @implicit_conv3d_kernel
.visible .entry implicit_conv3d_kernel(
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_0,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_1,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_2,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_3,
	.param .u32 implicit_conv3d_kernel_param_4,
	.param .u32 implicit_conv3d_kernel_param_5,
	.param .u32 implicit_conv3d_kernel_param_6,
	.param .u32 implicit_conv3d_kernel_param_7,
	.param .u32 implicit_conv3d_kernel_param_8,
	.param .u64 .ptr .global .align 1 implicit_conv3d_kernel_param_9
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<136>;
	.reg .b16 	%rs<499>;
	.reg .b32 	%r<603>;
	.reg .b64 	%rd<120>;
	.loc	1 33 0                          // implicit_gemm_kernel.py:33:0
$L__func_begin0:
	.loc	1 33 0                          // implicit_gemm_kernel.py:33:0

// %bb.0:
	ld.param.u32 	%r69, [implicit_conv3d_kernel_param_7];
	ld.param.u32 	%r67, [implicit_conv3d_kernel_param_5];
	ld.param.u64 	%rd20, [implicit_conv3d_kernel_param_3];
$L__tmp0:
	.loc	1 49 24                         // implicit_gemm_kernel.py:49:24
	mov.u32 	%r70, %ctaid.x;
	.loc	1 50 36                         // implicit_gemm_kernel.py:50:36
	shr.u32 	%r71, %r70, 31;
	add.s32 	%r72, %r70, %r71;
	and.b32  	%r73, %r72, -2;
	sub.s32 	%r597, %r70, %r73;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22
	add.s32 	%r74, %r67, 127;
$L__tmp2:
	.loc	1 49 35                         // implicit_gemm_kernel.py:49:35
	shr.s32 	%r75, %r72, 1;
	shr.s32 	%r77, %r74, 31;
	shr.u32 	%r78, %r77, 25;
	add.s32 	%r79, %r74, %r78;
	shr.s32 	%r80, %r79, 7;
	ld.param.u32 	%r81, [implicit_conv3d_kernel_param_8];
	.loc	1 54 20                         // implicit_gemm_kernel.py:54:20
	div.s32 	%r2, %r75, %r80;
	.loc	1 53 18                         // implicit_gemm_kernel.py:53:18
	mul.lo.s32 	%r82, %r2, %r80;
	sub.s32 	%r83, %r75, %r82;
	.loc	1 56 19                         // implicit_gemm_kernel.py:56:19
	mul.lo.s32 	%r84, %r81, %r81;
	.loc	1 56 23                         // implicit_gemm_kernel.py:56:23
	mul.lo.s32 	%r3, %r84, %r81;
	.loc	1 58 38                         // implicit_gemm_kernel.py:58:38
	mov.u32 	%r4, %tid.x;
	and.b32  	%r5, %r4, 31;
	and.b32  	%r6, %r4, 16;
	and.b32  	%r7, %r4, 64;
	.loc	1 58 57                         // implicit_gemm_kernel.py:58:57
	shl.b32 	%r9, %r83, 7;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	setp.lt.s32 	%p9, %r597, %r3;
	shr.u32 	%r11, %r4, 2;
	mov.u32 	%r595, global_smem;
	@%p9 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:                              // %.lr.ph12
	.loc	1 0 39                          // implicit_gemm_kernel.py:0:39
	ld.param.u32 	%r68, [implicit_conv3d_kernel_param_6];
	ld.param.u32 	%r66, [implicit_conv3d_kernel_param_4];
	ld.param.u64 	%rd19, [implicit_conv3d_kernel_param_2];
	ld.param.u64 	%rd18, [implicit_conv3d_kernel_param_0];
	ld.param.u64 	%rd21, [implicit_conv3d_kernel_param_1];
	.loc	1 58 0                          // implicit_gemm_kernel.py:58:0
	and.b32  	%r8, %r4, 127;
	or.b32  	%r10, %r9, %r8;
	mul.lo.s32 	%r85, %r10, %r3;
	mul.wide.s32 	%rd22, %r85, 4;
	add.s64 	%rd1, %rd21, %rd22;
	.loc	1 58 38                         // implicit_gemm_kernel.py:58:38
	and.b32  	%r87, %r4, 15;
	shr.u32 	%r602, %r4, 5;
	and.b32  	%r88, %r11, 15;
	shr.u32 	%r89, %r7, 2;
	or.b32  	%r16, %r88, %r89;
	shl.b32 	%r90, %r8, 2;
	add.s32 	%r123, %r595, %r90;
	shl.b32 	%r92, %r16, 2;
	add.s32 	%r18, %r595, %r92;
	bfe.u32 	%r93, %r4, 5, 2;
	add.s32 	%r125, %r595, %r93;
	setp.lt.s32 	%p10, %r4, 4;
	add.s32 	%r126, %r595, %r4;
	and.b32  	%r94, %r4, 3;
	setp.eq.s32 	%p11, %r94, 0;
	and.pred  	%p19, %p10, %p11;
	add.s32 	%r21, %r68, 31;
	shr.s32 	%r95, %r21, 31;
	shr.u32 	%r96, %r95, 27;
	add.s32 	%r97, %r21, %r96;
	shr.s32 	%r98, %r97, 5;
	shl.b32 	%r99, %r4, 3;
	and.b32  	%r22, %r99, 24;
	add.s32 	%r138, %r595, %r8;
	add.s32 	%r24, %r595, %r16;
	shl.b32 	%r601, %r2, 5;
	mul.lo.s32 	%r26, %r3, %r68;
	or.b32  	%r27, %r601, %r22;
	setp.lt.s32 	%p12, %r27, %r69;
	setp.gt.s32 	%p13, %r21, 31;
	setp.lt.s32 	%p14, %r22, %r68;
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	and.pred  	%p2, %p14, %p13;
	xor.b32  	%r100, %r99, %r4;
	and.b32  	%r101, %r100, 24;
	shl.b32 	%r102, %r16, 6;
	shl.b32 	%r103, %r101, 1;
	or.b32  	%r104, %r102, %r103;
	add.s32 	%r139, %r595, %r104;
	add.s32 	%r141, %r139, 2048;
	add.s32 	%r143, %r139, 4096;
	add.s32 	%r145, %r139, 6144;
	add.s32 	%r147, %r139, 8192;
	add.s32 	%r105, %r98, -1;
	shl.b32 	%r106, %r4, 2;
	and.b32  	%r107, %r106, 8;
	and.b32  	%r108, %r106, 16;
	and.b32  	%r109, %r106, 24;
	shr.u32 	%r110, %r6, 1;
	xor.b32  	%r33, %r109, %r110;
	shr.u32 	%r111, %r4, 1;
	and.b32  	%r600, %r111, 48;
	or.b32  	%r112, %r600, %r87;
	shl.b32 	%r35, %r112, 5;
	or.b32  	%r36, %r33, %r35;
	or.b32  	%r113, %r107, 16;
	xor.b32  	%r114, %r113, %r108;
	xor.b32  	%r37, %r114, %r110;
	or.b32  	%r38, %r37, %r35;
	shl.b32 	%r115, %r5, 5;
	or.b32  	%r39, %r109, %r115;
	xor.b32  	%r40, %r39, 8;
	or.b32  	%r41, %r114, %r115;
	xor.b32  	%r42, %r39, 24;
	cvt.s64.s32 	%rd2, %r105;
	cvt.u64.u32 	%rd23, %r22;
	cvt.s64.s32 	%rd3, %r68;
	cvt.u64.u32 	%rd4, %r98;
	and.pred  	%p3, %p12, %p13;
	or.b64  	%rd5, %rd23, 32;
	mad.lo.s32 	%r116, %r597, %r68, %r89;
	add.s32 	%r117, %r116, %r88;
	add.s32 	%r118, %r117, 32;
	cvt.u64.u32 	%rd117, %r118;
	shl.b32 	%r119, %r68, 1;
	cvt.u64.u32 	%rd7, %r119;
	mad.lo.s32 	%r120, %r69, %r118, %r601;
	add.s32 	%r596, %r120, %r22;
	mul.lo.s32 	%r121, %r69, %r68;
	shl.b32 	%r44, %r121, 1;
	shl.b32 	%r45, %r69, 5;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	or.b32  	%r46, %r22, 32;
	mov.b16 	%rs403, 0x0000;
	shl.b32 	%r379, %r36, 1;
	shl.b32 	%r380, %r38, 1;
	shl.b32 	%r391, %r40, 1;
	shl.b32 	%r392, %r41, 1;
	shl.b32 	%r393, %r42, 1;
	mov.u16 	%rs404, %rs403;
	mov.u16 	%rs405, %rs403;
	mov.u16 	%rs406, %rs403;
	mov.u16 	%rs407, %rs403;
	mov.u16 	%rs408, %rs403;
	mov.u16 	%rs409, %rs403;
	mov.u16 	%rs410, %rs403;
	mov.u16 	%rs411, %rs403;
	mov.u16 	%rs412, %rs403;
	mov.u16 	%rs413, %rs403;
	mov.u16 	%rs414, %rs403;
	mov.u16 	%rs415, %rs403;
	mov.u16 	%rs416, %rs403;
	mov.u16 	%rs417, %rs403;
	mov.u16 	%rs418, %rs403;
	mov.u16 	%rs419, %rs403;
	mov.u16 	%rs420, %rs403;
	mov.u16 	%rs421, %rs403;
	mov.u16 	%rs422, %rs403;
	mov.u16 	%rs423, %rs403;
	mov.u16 	%rs424, %rs403;
	mov.u16 	%rs425, %rs403;
	mov.u16 	%rs426, %rs403;
	mov.u16 	%rs427, %rs403;
	mov.u16 	%rs428, %rs403;
	mov.u16 	%rs429, %rs403;
	mov.u16 	%rs430, %rs403;
	mov.u16 	%rs431, %rs403;
	mov.u16 	%rs432, %rs403;
	mov.u16 	%rs433, %rs403;
	mov.u16 	%rs434, %rs403;
	bra.uni 	$L__BB0_3;
$L__BB0_7:                              // %._crit_edge
                                        //   in Loop: Header=BB0_3 Depth=1
	cp.async.wait_group 0;
	bar.sync 	0;
$L__BB0_8:                              //   in Loop: Header=BB0_3 Depth=1
	.loc	1 60 39                         // implicit_gemm_kernel.py:60:39
	add.s32 	%r597, %r597, 2;
	add.s64 	%rd117, %rd117, %rd7;
	add.s32 	%r596, %r596, %r44;
	setp.lt.s32 	%p38, %r597, %r3;
	@%p38 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_9;
$L__BB0_3:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_6 Depth 2
	.loc	1 0 39                          // implicit_gemm_kernel.py:0:39
	setp.eq.s32 	%p17, %r5, 0;
	.loc	1 63 85                         // implicit_gemm_kernel.py:63:85
	setp.lt.s32 	%p15, %r10, %r67;
	.loc	1 63 33                         // implicit_gemm_kernel.py:63:33
	mul.wide.s32 	%rd25, %r597, 4;
	add.s64 	%rd24, %rd1, %rd25;
	.loc	1 63 23                         // implicit_gemm_kernel.py:63:23
	// begin inline asm
	mov.u32 %r124, 0xffffffffffffffff;
	@%p15 ld.global.b32 { %r124 }, [ %rd24 + 0 ];
	// end inline asm
	.loc	1 69 56                         // implicit_gemm_kernel.py:69:56
	bar.sync 	0;
	mov.pred 	%p16, -1;
	// begin inline asm
	@%p16 st.shared.b32 [ %r123 + 0 ], %r124;
	// end inline asm
	bar.sync 	0;
	ld.shared.u32 	%r49, [%r18];
	ld.shared.u32 	%r50, [%r18+128];
	ld.shared.u32 	%r51, [%r18+256];
	ld.shared.u32 	%r52, [%r18+384];
	.loc	1 65 27                         // implicit_gemm_kernel.py:65:27
	setp.gt.s32 	%p20, %r124, -1;
	.loc	1 65 43                         // implicit_gemm_kernel.py:65:43
	setp.lt.s32 	%p21, %r124, %r66;
	.loc	1 65 36                         // implicit_gemm_kernel.py:65:36
	and.pred  	%p4, %p20, %p21;
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	bar.sync 	0;
	selp.u32 	%r128, 1, 0, %p4;
	mov.b32 	%r129, -1;
	redux.sync.or.b32 %r130, %r128, %r129;
	cvt.u16.u32 	%rs230, %r130;
	and.b16  	%rs227, %rs230, 1;
	// begin inline asm
	@%p17 st.shared.b8 [ %r125 + 0 ], %rs227;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p10 ld.shared.b8 %rs228, [ %r126 + 0 ];
	// end inline asm
	cvt.u32.u16 	%r131, %rs228;
	and.b16  	%rs231, %rs228, 1;
	setp.eq.b16 	%p22, %rs231, 1;
	and.b32  	%r132, %r131, 1;
	shfl.sync.bfly.b32	%r133, %r132, 2, 31, -1;
	and.b32  	%r134, %r133, 1;
	setp.eq.b32 	%p23, %r134, 1;
$L__tmp3:
	.loc	1 6 15                          // implicit_gemm_kernel.py:6:15
	or.pred  	%p24, %p22, %p23;
$L__tmp4:
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	selp.u32 	%r135, 1, 0, %p24;
	shfl.sync.bfly.b32	%r136, %r135, 1, 31, -1;
	and.b32  	%r137, %r136, 1;
	setp.eq.b32 	%p25, %r137, 1;
$L__tmp5:
	.loc	1 6 15                          // implicit_gemm_kernel.py:6:15
	or.pred  	%p26, %p24, %p25;
$L__tmp6:
	.loc	1 65 50                         // implicit_gemm_kernel.py:65:50
	selp.u16 	%rs229, 1, 0, %p26;
	// begin inline asm
	@%p19 st.shared.b8 [ %r126 + 0 ], %rs229;
	// end inline asm
	bar.sync 	0;
	ld.shared.u8 	%rs232, [global_smem];
	and.b16  	%rs233, %rs232, 1;
	setp.eq.b16 	%p27, %rs233, 1;
	.loc	1 65 11                         // implicit_gemm_kernel.py:65:11
	not.pred 	%p28, %p27;
	@%p28 bra 	$L__BB0_8;
// %bb.4:                               //   in Loop: Header=BB0_3 Depth=1
	.loc	1 0 11                          // implicit_gemm_kernel.py:0:11
	setp.lt.s32 	%p30, %r21, 32;
	.loc	1 69 52                         // implicit_gemm_kernel.py:69:52
	mul.lo.s32 	%r53, %r49, %r68;
	mul.lo.s32 	%r54, %r50, %r68;
	mul.lo.s32 	%r55, %r51, %r68;
	mul.lo.s32 	%r56, %r52, %r68;
	.loc	1 69 56                         // implicit_gemm_kernel.py:69:56
	add.s32 	%r149, %r53, %r22;
	add.s32 	%r150, %r54, %r22;
	add.s32 	%r151, %r55, %r22;
	add.s32 	%r152, %r56, %r22;
	.loc	1 70 64                         // implicit_gemm_kernel.py:70:64
	bar.sync 	0;
	selp.u16 	%rs234, 1, 0, %p4;
	// begin inline asm
	@%p16 st.shared.b8 [ %r138 + 0 ], %rs234;
	// end inline asm
	bar.sync 	0;
	ld.shared.u8 	%rs235, [%r24];
	ld.shared.u8 	%rs236, [%r24+32];
	ld.shared.u8 	%rs237, [%r24+64];
	ld.shared.u8 	%rs238, [%r24+96];
	and.b16  	%rs239, %rs235, 1;
	setp.eq.b16 	%p5, %rs239, 1;
	and.b16  	%rs240, %rs236, 1;
	setp.eq.b16 	%p6, %rs240, 1;
	and.b16  	%rs241, %rs237, 1;
	setp.eq.b16 	%p7, %rs241, 1;
	and.b16  	%rs242, %rs238, 1;
	setp.eq.b16 	%p8, %rs242, 1;
	.loc	1 69 36                         // implicit_gemm_kernel.py:69:36
	mul.wide.s32 	%rd31, %r149, 2;
	add.s64 	%rd26, %rd18, %rd31;
	mul.wide.s32 	%rd32, %r150, 2;
	add.s64 	%rd27, %rd18, %rd32;
	mul.wide.s32 	%rd33, %r151, 2;
	add.s64 	%rd28, %rd18, %rd33;
	mul.wide.s32 	%rd34, %r152, 2;
	add.s64 	%rd29, %rd18, %rd34;
	.loc	1 73 54                         // implicit_gemm_kernel.py:73:54
	mad.lo.s32 	%r153, %r597, %r68, %r16;
	.loc	1 75 22                         // implicit_gemm_kernel.py:75:22
	mad.lo.s32 	%r154, %r153, %r69, %r27;
	.loc	1 73 20                         // implicit_gemm_kernel.py:73:20
	mul.wide.s32 	%rd35, %r154, 2;
	add.s64 	%rd30, %rd19, %rd35;
	.loc	1 77 72                         // implicit_gemm_kernel.py:77:72
	setp.lt.s32 	%p31, %r153, %r26;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	bar.sync 	0;
	selp.b32 	%r155, 16, 0, %p5;
	selp.b32 	%r140, %r155, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r139 + 0 ], [ %rd26 + 0 ], 0x10, %r140;
	// end inline asm
	selp.b32 	%r156, 16, 0, %p6;
	selp.b32 	%r142, %r156, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r141 + 0 ], [ %rd27 + 0 ], 0x10, %r142;
	// end inline asm
	selp.b32 	%r157, 16, 0, %p7;
	selp.b32 	%r144, %r157, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r143 + 0 ], [ %rd28 + 0 ], 0x10, %r144;
	// end inline asm
	selp.b32 	%r158, 16, 0, %p8;
	selp.b32 	%r146, %r158, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r145 + 0 ], [ %rd29 + 0 ], 0x10, %r146;
	// end inline asm
	cp.async.commit_group;
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	selp.b32 	%r159, 16, 0, %p3;
	selp.b32 	%r148, %r159, 0, %p31;
	// begin inline asm
	cp.async.cg.shared.global [ %r147 + 0 ], [ %rd30 + 0 ], 0x10, %r148;
	// end inline asm
	cp.async.commit_group;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	@%p30 bra 	$L__BB0_7;
// %bb.5:                               // %.lr.ph.preheader
                                        //   in Loop: Header=BB0_3 Depth=1
	add.s32 	%r161, %r46, %r56;
	cvt.u64.u32 	%rd9, %r161;
	add.s32 	%r162, %r46, %r55;
	cvt.u64.u32 	%rd10, %r162;
	add.s32 	%r163, %r46, %r54;
	cvt.u64.u32 	%rd11, %r163;
	add.s32 	%r164, %r46, %r53;
	cvt.u64.u32 	%rd12, %r164;
	mov.b32 	%r599, -1;
	mov.b64 	%rd118, 0;
	mov.u32 	%r598, %r596;
	mov.u64 	%rd119, %rd118;
$L__BB0_6:                              // %.lr.ph
                                        //   Parent Loop BB0_3 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	setp.lt.s64 	%p33, %rd119, %rd2;
	add.s32 	%r375, %r599, 1;
	setp.gt.u32 	%p34, %r599, 2147483646;
	selp.b32 	%r599, %r375, 0, %p34;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	cp.async.wait_group 0;
	bar.sync 	0;
	shl.b32 	%r376, %r599, 13;
	add.s32 	%r378, %r595, %r376;
	add.s32 	%r169, %r378, %r379;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r209, %r210, %r211, %r212}, [%r169];
	// end inline asm
	add.s32 	%r174, %r378, %r380;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r289, %r290, %r291, %r292}, [%r174];
	// end inline asm
	add.s32 	%r381, %r35, %r33;
	shl.b32 	%r382, %r381, 1;
	add.s32 	%r383, %r378, %r382;
	add.s32 	%r179, %r383, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r249, %r250, %r251, %r252}, [%r179];
	// end inline asm
	add.s32 	%r384, %r37, %r35;
	shl.b32 	%r385, %r384, 1;
	add.s32 	%r386, %r378, %r385;
	add.s32 	%r184, %r386, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r329, %r330, %r331, %r332}, [%r184];
	// end inline asm
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	shl.b32 	%r387, %r599, 11;
	add.s32 	%r388, %r595, %r387;
	add.s32 	%r389, %r388, 8192;
	shl.b32 	%r390, %r39, 1;
	add.s32 	%r189, %r389, %r390;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r213, %r214, %r293, %r294}, [%r189];
	// end inline asm
	add.s32 	%r194, %r389, %r391;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r223, %r224, %r303, %r304}, [%r194];
	// end inline asm
	add.s32 	%r199, %r389, %r392;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r233, %r234, %r313, %r314}, [%r199];
	// end inline asm
	add.s32 	%r204, %r389, %r393;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r243, %r244, %r323, %r324}, [%r204];
	// end inline asm
	.loc	1 84 37                         // implicit_gemm_kernel.py:84:37
	mov.b32 	%r285, {%rs403, %rs404};
	mov.b32 	%r286, {%rs405, %rs406};
	mov.b32 	%r295, {%rs407, %rs408};
	mov.b32 	%r296, {%rs409, %rs410};
	mov.b32 	%r305, {%rs411, %rs412};
	mov.b32 	%r306, {%rs413, %rs414};
	mov.b32 	%r315, {%rs415, %rs416};
	mov.b32 	%r316, {%rs417, %rs418};
	mov.b32 	%r325, {%rs419, %rs420};
	mov.b32 	%r326, {%rs421, %rs422};
	mov.b32 	%r335, {%rs423, %rs424};
	mov.b32 	%r336, {%rs425, %rs426};
	mov.b32 	%r345, {%rs427, %rs428};
	mov.b32 	%r346, {%rs429, %rs430};
	mov.b32 	%r355, {%rs431, %rs432};
	mov.b32 	%r356, {%rs433, %rs434};
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r285, %r286 }, { %r209, %r210, %r211, %r212 }, { %r213, %r214 }, { %r285, %r286 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r295, %r296 }, { %r209, %r210, %r211, %r212 }, { %r223, %r224 }, { %r295, %r296 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r305, %r306 }, { %r209, %r210, %r211, %r212 }, { %r233, %r234 }, { %r305, %r306 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r315, %r316 }, { %r209, %r210, %r211, %r212 }, { %r243, %r244 }, { %r315, %r316 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r325, %r326 }, { %r249, %r250, %r251, %r252 }, { %r213, %r214 }, { %r325, %r326 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r335, %r336 }, { %r249, %r250, %r251, %r252 }, { %r223, %r224 }, { %r335, %r336 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r345, %r346 }, { %r249, %r250, %r251, %r252 }, { %r233, %r234 }, { %r345, %r346 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r355, %r356 }, { %r249, %r250, %r251, %r252 }, { %r243, %r244 }, { %r355, %r356 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r285, %r286 }, { %r289, %r290, %r291, %r292 }, { %r293, %r294 }, { %r285, %r286 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r295, %r296 }, { %r289, %r290, %r291, %r292 }, { %r303, %r304 }, { %r295, %r296 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r305, %r306 }, { %r289, %r290, %r291, %r292 }, { %r313, %r314 }, { %r305, %r306 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r315, %r316 }, { %r289, %r290, %r291, %r292 }, { %r323, %r324 }, { %r315, %r316 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r325, %r326 }, { %r329, %r330, %r331, %r332 }, { %r293, %r294 }, { %r325, %r326 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r335, %r336 }, { %r329, %r330, %r331, %r332 }, { %r303, %r304 }, { %r335, %r336 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r345, %r346 }, { %r329, %r330, %r331, %r332 }, { %r313, %r314 }, { %r345, %r346 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r355, %r356 }, { %r329, %r330, %r331, %r332 }, { %r323, %r324 }, { %r355, %r356 };
	// end inline asm
	mov.b32 	{%rs403, %rs404}, %r285;
	mov.b32 	{%rs405, %rs406}, %r286;
	mov.b32 	{%rs407, %rs408}, %r295;
	mov.b32 	{%rs409, %rs410}, %r296;
	mov.b32 	{%rs411, %rs412}, %r305;
	mov.b32 	{%rs413, %rs414}, %r306;
	mov.b32 	{%rs415, %rs416}, %r315;
	mov.b32 	{%rs417, %rs418}, %r316;
	mov.b32 	{%rs419, %rs420}, %r325;
	mov.b32 	{%rs421, %rs422}, %r326;
	mov.b32 	{%rs423, %rs424}, %r335;
	mov.b32 	{%rs425, %rs426}, %r336;
	mov.b32 	{%rs427, %rs428}, %r345;
	mov.b32 	{%rs429, %rs430}, %r346;
	mov.b32 	{%rs431, %rs432}, %r355;
	mov.b32 	{%rs433, %rs434}, %r356;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	add.s64 	%rd119, %rd119, 1;
	.loc	1 69 89                         // implicit_gemm_kernel.py:69:89
	add.s64 	%rd42, %rd12, %rd118;
	add.s64 	%rd43, %rd11, %rd118;
	add.s64 	%rd44, %rd10, %rd118;
	.loc	1 69 36                         // implicit_gemm_kernel.py:69:36
	add.s64 	%rd45, %rd9, %rd118;
	cvt.u32.u64 	%r394, %rd42;
	mul.wide.s32 	%rd46, %r394, 2;
	add.s64 	%rd37, %rd18, %rd46;
	cvt.u32.u64 	%r395, %rd43;
	mul.wide.s32 	%rd47, %r395, 2;
	add.s64 	%rd38, %rd18, %rd47;
	cvt.u32.u64 	%r396, %rd44;
	mul.wide.s32 	%rd48, %r396, 2;
	add.s64 	%rd39, %rd18, %rd48;
	cvt.u32.u64 	%r397, %rd45;
	mul.wide.s32 	%rd49, %r397, 2;
	add.s64 	%rd40, %rd18, %rd49;
	.loc	1 70 112                        // implicit_gemm_kernel.py:70:112
	add.s64 	%rd50, %rd5, %rd118;
	setp.lt.s64 	%p35, %rd50, %rd3;
	.loc	1 73 66                         // implicit_gemm_kernel.py:73:66
	add.s64 	%rd51, %rd117, %rd118;
	.loc	1 73 20                         // implicit_gemm_kernel.py:73:20
	mul.wide.s32 	%rd52, %r598, 2;
	add.s64 	%rd41, %rd19, %rd52;
	cvt.u32.u64 	%r398, %rd51;
	.loc	1 77 72                         // implicit_gemm_kernel.py:77:72
	setp.lt.s32 	%p36, %r398, %r26;
	.loc	1 81 39                         // implicit_gemm_kernel.py:81:39
	bar.sync 	0;
	selp.b32 	%r400, %r155, 0, %p35;
	selp.b32 	%r366, %r400, 0, %p33;
	// begin inline asm
	cp.async.cg.shared.global [ %r139 + 0 ], [ %rd37 + 0 ], 0x10, %r366;
	// end inline asm
	selp.b32 	%r402, %r156, 0, %p35;
	selp.b32 	%r368, %r402, 0, %p33;
	// begin inline asm
	cp.async.cg.shared.global [ %r141 + 0 ], [ %rd38 + 0 ], 0x10, %r368;
	// end inline asm
	selp.b32 	%r404, %r157, 0, %p35;
	selp.b32 	%r370, %r404, 0, %p33;
	// begin inline asm
	cp.async.cg.shared.global [ %r143 + 0 ], [ %rd39 + 0 ], 0x10, %r370;
	// end inline asm
	selp.b32 	%r406, %r158, 0, %p35;
	selp.b32 	%r372, %r406, 0, %p33;
	// begin inline asm
	cp.async.cg.shared.global [ %r145 + 0 ], [ %rd40 + 0 ], 0x10, %r372;
	// end inline asm
	cp.async.commit_group;
	.loc	1 82 36                         // implicit_gemm_kernel.py:82:36
	selp.b32 	%r407, 16, 0, %p36;
	selp.b32 	%r408, %r407, 0, %p12;
	selp.b32 	%r374, %r408, 0, %p33;
	// begin inline asm
	cp.async.cg.shared.global [ %r147 + 0 ], [ %rd41 + 0 ], 0x10, %r374;
	// end inline asm
	cp.async.commit_group;
	.loc	1 66 28                         // implicit_gemm_kernel.py:66:28
	add.s64 	%rd118, %rd118, 32;
	add.s32 	%r598, %r598, %r45;
	setp.ne.s64 	%p37, %rd4, %rd119;
	@%p37 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_7;
$L__BB0_1:                              // %.._crit_edge13_crit_edge
	.loc	1 86 31                         // implicit_gemm_kernel.py:86:31
	shr.u32 	%r602, %r4, 5;
	.loc	1 88 19                         // implicit_gemm_kernel.py:88:19
	shl.b32 	%r601, %r2, 5;
	.loc	1 99 12                         // implicit_gemm_kernel.py:99:12
	shr.u32 	%r86, %r4, 1;
	and.b32  	%r600, %r86, 48;
	mov.b16 	%rs403, 0;
	mov.u16 	%rs404, %rs403;
	mov.u16 	%rs405, %rs403;
	mov.u16 	%rs406, %rs403;
	mov.u16 	%rs407, %rs403;
	mov.u16 	%rs408, %rs403;
	mov.u16 	%rs409, %rs403;
	mov.u16 	%rs410, %rs403;
	mov.u16 	%rs411, %rs403;
	mov.u16 	%rs412, %rs403;
	mov.u16 	%rs413, %rs403;
	mov.u16 	%rs414, %rs403;
	mov.u16 	%rs415, %rs403;
	mov.u16 	%rs416, %rs403;
	mov.u16 	%rs417, %rs403;
	mov.u16 	%rs418, %rs403;
	mov.u16 	%rs419, %rs403;
	mov.u16 	%rs420, %rs403;
	mov.u16 	%rs421, %rs403;
	mov.u16 	%rs422, %rs403;
	mov.u16 	%rs423, %rs403;
	mov.u16 	%rs424, %rs403;
	mov.u16 	%rs425, %rs403;
	mov.u16 	%rs426, %rs403;
	mov.u16 	%rs427, %rs403;
	mov.u16 	%rs428, %rs403;
	mov.u16 	%rs429, %rs403;
	mov.u16 	%rs430, %rs403;
	mov.u16 	%rs431, %rs403;
	mov.u16 	%rs432, %rs403;
	mov.u16 	%rs433, %rs403;
	mov.u16 	%rs434, %rs403;
$L__BB0_9:                              // %._crit_edge13
	.loc	1 86 31                         // implicit_gemm_kernel.py:86:31
	and.b32  	%r441, %r602, 1;
	shr.u32 	%r442, %r7, 5;
	or.b32  	%r443, %r441, %r442;
	.loc	1 86 42                         // implicit_gemm_kernel.py:86:42
	or.b32  	%r444, %r443, %r9;
	or.b32  	%r445, %r444, 4;
	or.b32  	%r446, %r444, 8;
	or.b32  	%r447, %r444, 12;
	or.b32  	%r448, %r444, 16;
	or.b32  	%r449, %r444, 20;
	or.b32  	%r450, %r444, 24;
	or.b32  	%r451, %r444, 28;
	or.b32  	%r452, %r444, 32;
	or.b32  	%r453, %r444, 36;
	or.b32  	%r454, %r444, 40;
	or.b32  	%r455, %r444, 44;
	or.b32  	%r456, %r444, 48;
	or.b32  	%r457, %r444, 52;
	or.b32  	%r458, %r444, 56;
	or.b32  	%r459, %r444, 60;
	or.b32  	%r460, %r444, 64;
	or.b32  	%r461, %r444, 68;
	or.b32  	%r462, %r444, 72;
	or.b32  	%r463, %r444, 76;
	or.b32  	%r464, %r444, 80;
	or.b32  	%r465, %r444, 84;
	or.b32  	%r466, %r444, 88;
	or.b32  	%r467, %r444, 92;
	or.b32  	%r468, %r444, 96;
	or.b32  	%r469, %r444, 100;
	or.b32  	%r470, %r444, 104;
	or.b32  	%r471, %r444, 108;
	or.b32  	%r472, %r444, 112;
	or.b32  	%r473, %r444, 116;
	or.b32  	%r474, %r444, 120;
	or.b32  	%r475, %r444, 124;
	.loc	1 86 61                         // implicit_gemm_kernel.py:86:61
	mul.lo.s32 	%r476, %r444, %r69;
	shl.b32 	%r477, %r69, 2;
	add.s32 	%r478, %r476, %r477;
	add.s32 	%r479, %r478, %r477;
	add.s32 	%r480, %r479, %r477;
	add.s32 	%r481, %r480, %r477;
	add.s32 	%r482, %r481, %r477;
	add.s32 	%r483, %r482, %r477;
	add.s32 	%r484, %r483, %r477;
	add.s32 	%r485, %r484, %r477;
	add.s32 	%r486, %r485, %r477;
	add.s32 	%r487, %r486, %r477;
	add.s32 	%r488, %r487, %r477;
	add.s32 	%r489, %r488, %r477;
	add.s32 	%r490, %r489, %r477;
	add.s32 	%r491, %r490, %r477;
	add.s32 	%r492, %r491, %r477;
	add.s32 	%r493, %r492, %r477;
	add.s32 	%r494, %r493, %r477;
	add.s32 	%r495, %r494, %r477;
	add.s32 	%r496, %r495, %r477;
	add.s32 	%r497, %r496, %r477;
	add.s32 	%r498, %r497, %r477;
	add.s32 	%r499, %r498, %r477;
	add.s32 	%r500, %r499, %r477;
	add.s32 	%r501, %r500, %r477;
	add.s32 	%r502, %r501, %r477;
	add.s32 	%r503, %r502, %r477;
	add.s32 	%r504, %r503, %r477;
	add.s32 	%r505, %r504, %r477;
	add.s32 	%r506, %r505, %r477;
	add.s32 	%r507, %r506, %r477;
	add.s32 	%r508, %r507, %r477;
	.loc	1 87 10                         // implicit_gemm_kernel.py:87:10
	or.b32  	%r509, %r601, %r5;
	.loc	1 88 10                         // implicit_gemm_kernel.py:88:10
	add.s32 	%r510, %r509, %r476;
	add.s32 	%r511, %r509, %r478;
	add.s32 	%r512, %r509, %r479;
	add.s32 	%r513, %r509, %r480;
	add.s32 	%r514, %r509, %r481;
	add.s32 	%r515, %r509, %r482;
	add.s32 	%r516, %r509, %r483;
	add.s32 	%r517, %r509, %r484;
	add.s32 	%r518, %r509, %r485;
	add.s32 	%r519, %r509, %r486;
	add.s32 	%r520, %r509, %r487;
	add.s32 	%r521, %r509, %r488;
	add.s32 	%r522, %r509, %r489;
	add.s32 	%r523, %r509, %r490;
	add.s32 	%r524, %r509, %r491;
	add.s32 	%r525, %r509, %r492;
	add.s32 	%r526, %r509, %r493;
	add.s32 	%r527, %r509, %r494;
	add.s32 	%r528, %r509, %r495;
	add.s32 	%r529, %r509, %r496;
	add.s32 	%r530, %r509, %r497;
	add.s32 	%r531, %r509, %r498;
	add.s32 	%r532, %r509, %r499;
	add.s32 	%r533, %r509, %r500;
	add.s32 	%r534, %r509, %r501;
	add.s32 	%r535, %r509, %r502;
	add.s32 	%r536, %r509, %r503;
	add.s32 	%r537, %r509, %r504;
	add.s32 	%r538, %r509, %r505;
	add.s32 	%r539, %r509, %r506;
	add.s32 	%r540, %r509, %r507;
	add.s32 	%r541, %r509, %r508;
	.loc	1 86 8                          // implicit_gemm_kernel.py:86:8
	mul.wide.s32 	%rd85, %r510, 2;
	add.s64 	%rd53, %rd20, %rd85;
	mul.wide.s32 	%rd86, %r511, 2;
	add.s64 	%rd54, %rd20, %rd86;
	mul.wide.s32 	%rd87, %r512, 2;
	add.s64 	%rd55, %rd20, %rd87;
	mul.wide.s32 	%rd88, %r513, 2;
	add.s64 	%rd56, %rd20, %rd88;
	mul.wide.s32 	%rd89, %r514, 2;
	add.s64 	%rd57, %rd20, %rd89;
	mul.wide.s32 	%rd90, %r515, 2;
	add.s64 	%rd58, %rd20, %rd90;
	mul.wide.s32 	%rd91, %r516, 2;
	add.s64 	%rd59, %rd20, %rd91;
	mul.wide.s32 	%rd92, %r517, 2;
	add.s64 	%rd60, %rd20, %rd92;
	mul.wide.s32 	%rd93, %r518, 2;
	add.s64 	%rd61, %rd20, %rd93;
	mul.wide.s32 	%rd94, %r519, 2;
	add.s64 	%rd62, %rd20, %rd94;
	mul.wide.s32 	%rd95, %r520, 2;
	add.s64 	%rd63, %rd20, %rd95;
	mul.wide.s32 	%rd96, %r521, 2;
	add.s64 	%rd64, %rd20, %rd96;
	mul.wide.s32 	%rd97, %r522, 2;
	add.s64 	%rd65, %rd20, %rd97;
	mul.wide.s32 	%rd98, %r523, 2;
	add.s64 	%rd66, %rd20, %rd98;
	mul.wide.s32 	%rd99, %r524, 2;
	add.s64 	%rd67, %rd20, %rd99;
	mul.wide.s32 	%rd100, %r525, 2;
	add.s64 	%rd68, %rd20, %rd100;
	mul.wide.s32 	%rd101, %r526, 2;
	add.s64 	%rd69, %rd20, %rd101;
	mul.wide.s32 	%rd102, %r527, 2;
	add.s64 	%rd70, %rd20, %rd102;
	mul.wide.s32 	%rd103, %r528, 2;
	add.s64 	%rd71, %rd20, %rd103;
	mul.wide.s32 	%rd104, %r529, 2;
	add.s64 	%rd72, %rd20, %rd104;
	mul.wide.s32 	%rd105, %r530, 2;
	add.s64 	%rd73, %rd20, %rd105;
	mul.wide.s32 	%rd106, %r531, 2;
	add.s64 	%rd74, %rd20, %rd106;
	mul.wide.s32 	%rd107, %r532, 2;
	add.s64 	%rd75, %rd20, %rd107;
	mul.wide.s32 	%rd108, %r533, 2;
	add.s64 	%rd76, %rd20, %rd108;
	mul.wide.s32 	%rd109, %r534, 2;
	add.s64 	%rd77, %rd20, %rd109;
	mul.wide.s32 	%rd110, %r535, 2;
	add.s64 	%rd78, %rd20, %rd110;
	mul.wide.s32 	%rd111, %r536, 2;
	add.s64 	%rd79, %rd20, %rd111;
	mul.wide.s32 	%rd112, %r537, 2;
	add.s64 	%rd80, %rd20, %rd112;
	mul.wide.s32 	%rd113, %r538, 2;
	add.s64 	%rd81, %rd20, %rd113;
	mul.wide.s32 	%rd114, %r539, 2;
	add.s64 	%rd82, %rd20, %rd114;
	mul.wide.s32 	%rd115, %r540, 2;
	add.s64 	%rd83, %rd20, %rd115;
	mul.wide.s32 	%rd116, %r541, 2;
	add.s64 	%rd84, %rd20, %rd116;
	.loc	1 90 67                         // implicit_gemm_kernel.py:90:67
	setp.lt.s32 	%p103, %r444, %r67;
	setp.lt.s32 	%p104, %r445, %r67;
	setp.lt.s32 	%p105, %r446, %r67;
	setp.lt.s32 	%p106, %r447, %r67;
	setp.lt.s32 	%p107, %r448, %r67;
	setp.lt.s32 	%p108, %r449, %r67;
	setp.lt.s32 	%p109, %r450, %r67;
	setp.lt.s32 	%p110, %r451, %r67;
	setp.lt.s32 	%p111, %r452, %r67;
	setp.lt.s32 	%p112, %r453, %r67;
	setp.lt.s32 	%p113, %r454, %r67;
	setp.lt.s32 	%p114, %r455, %r67;
	setp.lt.s32 	%p115, %r456, %r67;
	setp.lt.s32 	%p116, %r457, %r67;
	setp.lt.s32 	%p117, %r458, %r67;
	setp.lt.s32 	%p118, %r459, %r67;
	setp.lt.s32 	%p119, %r460, %r67;
	setp.lt.s32 	%p120, %r461, %r67;
	setp.lt.s32 	%p121, %r462, %r67;
	setp.lt.s32 	%p122, %r463, %r67;
	setp.lt.s32 	%p123, %r464, %r67;
	setp.lt.s32 	%p124, %r465, %r67;
	setp.lt.s32 	%p125, %r466, %r67;
	setp.lt.s32 	%p126, %r467, %r67;
	setp.lt.s32 	%p127, %r468, %r67;
	setp.lt.s32 	%p128, %r469, %r67;
	setp.lt.s32 	%p129, %r470, %r67;
	setp.lt.s32 	%p130, %r471, %r67;
	setp.lt.s32 	%p131, %r472, %r67;
	setp.lt.s32 	%p132, %r473, %r67;
	setp.lt.s32 	%p133, %r474, %r67;
	setp.lt.s32 	%p134, %r475, %r67;
	.loc	1 91 62                         // implicit_gemm_kernel.py:91:62
	setp.lt.s32 	%p135, %r509, %r69;
	.loc	1 91 8                          // implicit_gemm_kernel.py:91:8
	and.pred  	%p71, %p103, %p135;
	and.pred  	%p72, %p104, %p135;
	and.pred  	%p73, %p105, %p135;
	and.pred  	%p74, %p106, %p135;
	and.pred  	%p75, %p107, %p135;
	and.pred  	%p76, %p108, %p135;
	and.pred  	%p77, %p109, %p135;
	and.pred  	%p78, %p110, %p135;
	and.pred  	%p79, %p111, %p135;
	and.pred  	%p80, %p112, %p135;
	and.pred  	%p81, %p113, %p135;
	and.pred  	%p82, %p114, %p135;
	and.pred  	%p83, %p115, %p135;
	and.pred  	%p84, %p116, %p135;
	and.pred  	%p85, %p117, %p135;
	and.pred  	%p86, %p118, %p135;
	and.pred  	%p87, %p119, %p135;
	and.pred  	%p88, %p120, %p135;
	and.pred  	%p89, %p121, %p135;
	and.pred  	%p90, %p122, %p135;
	and.pred  	%p91, %p123, %p135;
	and.pred  	%p92, %p124, %p135;
	and.pred  	%p93, %p125, %p135;
	and.pred  	%p94, %p126, %p135;
	and.pred  	%p95, %p127, %p135;
	and.pred  	%p96, %p128, %p135;
	and.pred  	%p97, %p129, %p135;
	and.pred  	%p98, %p130, %p135;
	and.pred  	%p99, %p131, %p135;
	and.pred  	%p100, %p132, %p135;
	and.pred  	%p101, %p133, %p135;
	and.pred  	%p102, %p134, %p135;
	.loc	1 99 12                         // implicit_gemm_kernel.py:99:12
	bar.sync 	0;
	shl.b32 	%r542, %r4, 7;
	and.b32  	%r543, %r542, 384;
	and.b32  	%r544, %r11, 3;
	shr.u32 	%r545, %r6, 2;
	or.b32  	%r546, %r545, %r600;
	or.b32  	%r547, %r546, %r544;
	or.b32  	%r548, %r547, %r543;
	shl.b32 	%r549, %r4, 6;
	and.b32  	%r550, %r549, 1984;
	or.b32  	%r551, %r443, %r550;
	shr.u32 	%r552, %r543, 5;
	add.s32 	%r554, %r595, %r552;
	shl.b32 	%r555, %r548, 1;
	add.s32 	%r409, %r554, %r555;
	mov.pred 	%p39, -1;
	// begin inline asm
	@%p39 st.shared.b16 [ %r409 + 0 ], %rs403;
	// end inline asm
	or.b32  	%r556, %r548, 64;
	shr.u32 	%r557, %r556, 5;
	and.b32  	%r558, %r557, 33554430;
	add.s32 	%r559, %r595, %r558;
	add.s32 	%r560, %r559, %r555;
	add.s32 	%r410, %r560, 128;
	// begin inline asm
	@%p39 st.shared.b16 [ %r410 + 0 ], %rs404;
	// end inline asm
	add.s32 	%r411, %r409, 16;
	// begin inline asm
	@%p39 st.shared.b16 [ %r411 + 0 ], %rs405;
	// end inline asm
	add.s32 	%r412, %r560, 144;
	// begin inline asm
	@%p39 st.shared.b16 [ %r412 + 0 ], %rs406;
	// end inline asm
	or.b32  	%r561, %r548, 512;
	shr.u32 	%r562, %r561, 5;
	and.b32  	%r563, %r562, 33554430;
	add.s32 	%r564, %r595, %r563;
	add.s32 	%r565, %r564, %r555;
	add.s32 	%r413, %r565, 1024;
	// begin inline asm
	@%p39 st.shared.b16 [ %r413 + 0 ], %rs407;
	// end inline asm
	or.b32  	%r566, %r548, 576;
	shr.u32 	%r567, %r566, 5;
	and.b32  	%r568, %r567, 33554430;
	add.s32 	%r569, %r595, %r568;
	add.s32 	%r570, %r569, %r555;
	add.s32 	%r414, %r570, 1152;
	// begin inline asm
	@%p39 st.shared.b16 [ %r414 + 0 ], %rs408;
	// end inline asm
	add.s32 	%r415, %r565, 1040;
	// begin inline asm
	@%p39 st.shared.b16 [ %r415 + 0 ], %rs409;
	// end inline asm
	add.s32 	%r416, %r570, 1168;
	// begin inline asm
	@%p39 st.shared.b16 [ %r416 + 0 ], %rs410;
	// end inline asm
	or.b32  	%r571, %r548, 1024;
	shr.u32 	%r572, %r571, 5;
	and.b32  	%r573, %r572, 33554430;
	add.s32 	%r574, %r595, %r573;
	add.s32 	%r575, %r574, %r555;
	add.s32 	%r417, %r575, 2048;
	// begin inline asm
	@%p39 st.shared.b16 [ %r417 + 0 ], %rs411;
	// end inline asm
	or.b32  	%r576, %r548, 1088;
	shr.u32 	%r577, %r576, 5;
	and.b32  	%r578, %r577, 33554430;
	add.s32 	%r579, %r595, %r578;
	add.s32 	%r580, %r579, %r555;
	add.s32 	%r418, %r580, 2176;
	// begin inline asm
	@%p39 st.shared.b16 [ %r418 + 0 ], %rs412;
	// end inline asm
	add.s32 	%r419, %r575, 2064;
	// begin inline asm
	@%p39 st.shared.b16 [ %r419 + 0 ], %rs413;
	// end inline asm
	add.s32 	%r420, %r580, 2192;
	// begin inline asm
	@%p39 st.shared.b16 [ %r420 + 0 ], %rs414;
	// end inline asm
	or.b32  	%r581, %r548, 1536;
	shr.u32 	%r582, %r581, 5;
	and.b32  	%r583, %r582, 33554430;
	add.s32 	%r584, %r595, %r583;
	add.s32 	%r585, %r584, %r555;
	add.s32 	%r421, %r585, 3072;
	// begin inline asm
	@%p39 st.shared.b16 [ %r421 + 0 ], %rs415;
	// end inline asm
	or.b32  	%r586, %r548, 1600;
	shr.u32 	%r587, %r586, 5;
	and.b32  	%r588, %r587, 33554430;
	add.s32 	%r589, %r595, %r588;
	add.s32 	%r590, %r589, %r555;
	add.s32 	%r422, %r590, 3200;
	// begin inline asm
	@%p39 st.shared.b16 [ %r422 + 0 ], %rs416;
	// end inline asm
	add.s32 	%r423, %r585, 3088;
	// begin inline asm
	@%p39 st.shared.b16 [ %r423 + 0 ], %rs417;
	// end inline asm
	add.s32 	%r424, %r590, 3216;
	// begin inline asm
	@%p39 st.shared.b16 [ %r424 + 0 ], %rs418;
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r591, %r550, 5;
	add.s32 	%r592, %r595, %r591;
	shl.b32 	%r593, %r551, 1;
	add.s32 	%r594, %r592, %r593;
	ld.shared.u16 	%rs276, [%r594];
	ld.shared.u16 	%rs278, [%r594+8];
	ld.shared.u16 	%rs280, [%r594+16];
	ld.shared.u16 	%rs282, [%r594+24];
	ld.shared.u16 	%rs284, [%r594+32];
	ld.shared.u16 	%rs286, [%r594+40];
	ld.shared.u16 	%rs288, [%r594+48];
	ld.shared.u16 	%rs290, [%r594+56];
	ld.shared.u16 	%rs292, [%r594+64];
	ld.shared.u16 	%rs294, [%r594+72];
	ld.shared.u16 	%rs296, [%r594+80];
	ld.shared.u16 	%rs298, [%r594+88];
	ld.shared.u16 	%rs300, [%r594+96];
	ld.shared.u16 	%rs302, [%r594+104];
	ld.shared.u16 	%rs304, [%r594+112];
	ld.shared.u16 	%rs306, [%r594+120];
	bar.sync 	0;
	// begin inline asm
	@%p39 st.shared.b16 [ %r409 + 0 ], %rs419;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r410 + 0 ], %rs420;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r411 + 0 ], %rs421;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r412 + 0 ], %rs422;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r413 + 0 ], %rs423;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r414 + 0 ], %rs424;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r415 + 0 ], %rs425;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r416 + 0 ], %rs426;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r417 + 0 ], %rs427;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r418 + 0 ], %rs428;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r419 + 0 ], %rs429;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r420 + 0 ], %rs430;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r421 + 0 ], %rs431;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r422 + 0 ], %rs432;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r423 + 0 ], %rs433;
	// end inline asm
	// begin inline asm
	@%p39 st.shared.b16 [ %r424 + 0 ], %rs434;
	// end inline asm
	bar.sync 	0;
	ld.shared.u16 	%rs308, [%r594];
	ld.shared.u16 	%rs310, [%r594+8];
	ld.shared.u16 	%rs312, [%r594+16];
	ld.shared.u16 	%rs314, [%r594+24];
	ld.shared.u16 	%rs316, [%r594+32];
	ld.shared.u16 	%rs318, [%r594+40];
	ld.shared.u16 	%rs320, [%r594+48];
	ld.shared.u16 	%rs322, [%r594+56];
	ld.shared.u16 	%rs324, [%r594+64];
	ld.shared.u16 	%rs326, [%r594+72];
	ld.shared.u16 	%rs328, [%r594+80];
	ld.shared.u16 	%rs330, [%r594+88];
	ld.shared.u16 	%rs332, [%r594+96];
	ld.shared.u16 	%rs334, [%r594+104];
	ld.shared.u16 	%rs336, [%r594+112];
	ld.shared.u16 	%rs338, [%r594+120];
	// begin inline asm
	mov.u16 %rs275, 0x0;
	@%p71 atom.global.gpu.acq_rel.add.noftz.f16 %rs275, [ %rd53 + 0 ], %rs276;
	// end inline asm
	// begin inline asm
	mov.u16 %rs277, 0x0;
	@%p72 atom.global.gpu.acq_rel.add.noftz.f16 %rs277, [ %rd54 + 0 ], %rs278;
	// end inline asm
	// begin inline asm
	mov.u16 %rs279, 0x0;
	@%p73 atom.global.gpu.acq_rel.add.noftz.f16 %rs279, [ %rd55 + 0 ], %rs280;
	// end inline asm
	// begin inline asm
	mov.u16 %rs281, 0x0;
	@%p74 atom.global.gpu.acq_rel.add.noftz.f16 %rs281, [ %rd56 + 0 ], %rs282;
	// end inline asm
	// begin inline asm
	mov.u16 %rs283, 0x0;
	@%p75 atom.global.gpu.acq_rel.add.noftz.f16 %rs283, [ %rd57 + 0 ], %rs284;
	// end inline asm
	// begin inline asm
	mov.u16 %rs285, 0x0;
	@%p76 atom.global.gpu.acq_rel.add.noftz.f16 %rs285, [ %rd58 + 0 ], %rs286;
	// end inline asm
	// begin inline asm
	mov.u16 %rs287, 0x0;
	@%p77 atom.global.gpu.acq_rel.add.noftz.f16 %rs287, [ %rd59 + 0 ], %rs288;
	// end inline asm
	// begin inline asm
	mov.u16 %rs289, 0x0;
	@%p78 atom.global.gpu.acq_rel.add.noftz.f16 %rs289, [ %rd60 + 0 ], %rs290;
	// end inline asm
	// begin inline asm
	mov.u16 %rs291, 0x0;
	@%p79 atom.global.gpu.acq_rel.add.noftz.f16 %rs291, [ %rd61 + 0 ], %rs292;
	// end inline asm
	// begin inline asm
	mov.u16 %rs293, 0x0;
	@%p80 atom.global.gpu.acq_rel.add.noftz.f16 %rs293, [ %rd62 + 0 ], %rs294;
	// end inline asm
	// begin inline asm
	mov.u16 %rs295, 0x0;
	@%p81 atom.global.gpu.acq_rel.add.noftz.f16 %rs295, [ %rd63 + 0 ], %rs296;
	// end inline asm
	// begin inline asm
	mov.u16 %rs297, 0x0;
	@%p82 atom.global.gpu.acq_rel.add.noftz.f16 %rs297, [ %rd64 + 0 ], %rs298;
	// end inline asm
	// begin inline asm
	mov.u16 %rs299, 0x0;
	@%p83 atom.global.gpu.acq_rel.add.noftz.f16 %rs299, [ %rd65 + 0 ], %rs300;
	// end inline asm
	// begin inline asm
	mov.u16 %rs301, 0x0;
	@%p84 atom.global.gpu.acq_rel.add.noftz.f16 %rs301, [ %rd66 + 0 ], %rs302;
	// end inline asm
	// begin inline asm
	mov.u16 %rs303, 0x0;
	@%p85 atom.global.gpu.acq_rel.add.noftz.f16 %rs303, [ %rd67 + 0 ], %rs304;
	// end inline asm
	// begin inline asm
	mov.u16 %rs305, 0x0;
	@%p86 atom.global.gpu.acq_rel.add.noftz.f16 %rs305, [ %rd68 + 0 ], %rs306;
	// end inline asm
	// begin inline asm
	mov.u16 %rs307, 0x0;
	@%p87 atom.global.gpu.acq_rel.add.noftz.f16 %rs307, [ %rd69 + 0 ], %rs308;
	// end inline asm
	// begin inline asm
	mov.u16 %rs309, 0x0;
	@%p88 atom.global.gpu.acq_rel.add.noftz.f16 %rs309, [ %rd70 + 0 ], %rs310;
	// end inline asm
	// begin inline asm
	mov.u16 %rs311, 0x0;
	@%p89 atom.global.gpu.acq_rel.add.noftz.f16 %rs311, [ %rd71 + 0 ], %rs312;
	// end inline asm
	// begin inline asm
	mov.u16 %rs313, 0x0;
	@%p90 atom.global.gpu.acq_rel.add.noftz.f16 %rs313, [ %rd72 + 0 ], %rs314;
	// end inline asm
	// begin inline asm
	mov.u16 %rs315, 0x0;
	@%p91 atom.global.gpu.acq_rel.add.noftz.f16 %rs315, [ %rd73 + 0 ], %rs316;
	// end inline asm
	// begin inline asm
	mov.u16 %rs317, 0x0;
	@%p92 atom.global.gpu.acq_rel.add.noftz.f16 %rs317, [ %rd74 + 0 ], %rs318;
	// end inline asm
	// begin inline asm
	mov.u16 %rs319, 0x0;
	@%p93 atom.global.gpu.acq_rel.add.noftz.f16 %rs319, [ %rd75 + 0 ], %rs320;
	// end inline asm
	// begin inline asm
	mov.u16 %rs321, 0x0;
	@%p94 atom.global.gpu.acq_rel.add.noftz.f16 %rs321, [ %rd76 + 0 ], %rs322;
	// end inline asm
	// begin inline asm
	mov.u16 %rs323, 0x0;
	@%p95 atom.global.gpu.acq_rel.add.noftz.f16 %rs323, [ %rd77 + 0 ], %rs324;
	// end inline asm
	// begin inline asm
	mov.u16 %rs325, 0x0;
	@%p96 atom.global.gpu.acq_rel.add.noftz.f16 %rs325, [ %rd78 + 0 ], %rs326;
	// end inline asm
	// begin inline asm
	mov.u16 %rs327, 0x0;
	@%p97 atom.global.gpu.acq_rel.add.noftz.f16 %rs327, [ %rd79 + 0 ], %rs328;
	// end inline asm
	// begin inline asm
	mov.u16 %rs329, 0x0;
	@%p98 atom.global.gpu.acq_rel.add.noftz.f16 %rs329, [ %rd80 + 0 ], %rs330;
	// end inline asm
	// begin inline asm
	mov.u16 %rs331, 0x0;
	@%p99 atom.global.gpu.acq_rel.add.noftz.f16 %rs331, [ %rd81 + 0 ], %rs332;
	// end inline asm
	// begin inline asm
	mov.u16 %rs333, 0x0;
	@%p100 atom.global.gpu.acq_rel.add.noftz.f16 %rs333, [ %rd82 + 0 ], %rs334;
	// end inline asm
	// begin inline asm
	mov.u16 %rs335, 0x0;
	@%p101 atom.global.gpu.acq_rel.add.noftz.f16 %rs335, [ %rd83 + 0 ], %rs336;
	// end inline asm
	// begin inline asm
	mov.u16 %rs337, 0x0;
	@%p102 atom.global.gpu.acq_rel.add.noftz.f16 %rs337, [ %rd84 + 0 ], %rs338;
	// end inline asm
	.loc	1 93 4                          // implicit_gemm_kernel.py:93:4
	ret;
$L__tmp7:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/allan/Programs/sparse-conv/implicit_gemm_kernel.py"
	.file	2 "/home/allan/anaconda3/envs/ml/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 174                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0xa7 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 105                                 // DW_AT_name
.b8 109
.b8 112
.b8 108
.b8 105
.b8 99
.b8 105
.b8 116
.b8 95
.b8 103
.b8 101
.b8 109
.b8 109
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 97
.b8 108
.b8 108
.b8 97
.b8 110
.b8 47
.b8 80
.b8 114
.b8 111
.b8 103
.b8 114
.b8 97
.b8 109
.b8 115
.b8 47
.b8 115
.b8 112
.b8 97
.b8 114
.b8 115
.b8 101
.b8 45
.b8 99
.b8 111
.b8 110
.b8 118
.b8 0
.b8 2                                   // Abbrev [2] 0x52:0x19 DW_TAG_subprogram
.b8 105                                 // DW_AT_name
.b8 109
.b8 112
.b8 108
.b8 105
.b8 99
.b8 105
.b8 116
.b8 95
.b8 99
.b8 111
.b8 110
.b8 118
.b8 51
.b8 100
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x6b:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 82                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x80:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 51                                  // DW_AT_call_line
.b8 30                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x98:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp6                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 65                                  // DW_AT_call_line
.b8 50                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
